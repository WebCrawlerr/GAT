{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a18a8cf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-05T19:47:13.098928Z",
     "iopub.status.busy": "2025-12-05T19:47:13.098252Z",
     "iopub.status.idle": "2025-12-05T19:47:14.022274Z",
     "shell.execute_reply": "2025-12-05T19:47:14.021146Z"
    },
    "papermill": {
     "duration": 0.929226,
     "end_time": "2025-12-05T19:47:14.023652",
     "exception": false,
     "start_time": "2025-12-05T19:47:13.094426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GAT'...\r\n",
      "remote: Enumerating objects: 112, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (112/112), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (75/75), done.\u001b[K\r\n",
      "remote: Total 112 (delta 59), reused 79 (delta 35), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (112/112), 89.72 KiB | 4.72 MiB/s, done.\r\n",
      "Resolving deltas: 100% (59/59), done.\r\n"
     ]
    }
   ],
   "source": [
    "# Znak wykrzyknika (!) pozwala wywołać komendy systemowe Linuxa\n",
    "!git clone https://github.com/WebCrawlerr/GAT.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbc35ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:47:14.030479Z",
     "iopub.status.busy": "2025-12-05T19:47:14.029772Z",
     "iopub.status.idle": "2025-12-05T19:47:14.147913Z",
     "shell.execute_reply": "2025-12-05T19:47:14.147242Z"
    },
    "papermill": {
     "duration": 0.122539,
     "end_time": "2025-12-05T19:47:14.149086",
     "exception": false,
     "start_time": "2025-12-05T19:47:14.026547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /kaggle)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "# Pobranie zmian\n",
    "!git pull origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c217ff4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:47:14.154838Z",
     "iopub.status.busy": "2025-12-05T19:47:14.154333Z",
     "iopub.status.idle": "2025-12-05T19:47:14.280008Z",
     "shell.execute_reply": "2025-12-05T19:47:14.279310Z"
    },
    "papermill": {
     "duration": 0.129903,
     "end_time": "2025-12-05T19:47:14.281202",
     "exception": false,
     "start_time": "2025-12-05T19:47:14.151299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT:\r\n",
      "main.py  models  requirements.txt  src\ttests\r\n",
      "\r\n",
      "GAT/models:\r\n",
      "best_model.pth\tfold_0_best_model.pth\r\n",
      "\r\n",
      "GAT/src:\r\n",
      "config.py\t    dataset.py\t model.py     __pycache__  utils.py\r\n",
      "data_processing.py  features.py  optimize.py  train.py\r\n",
      "\r\n",
      "GAT/src/__pycache__:\r\n",
      "config.cpython-312.pyc\t\t model.cpython-312.pyc\r\n",
      "data_processing.cpython-312.pyc  optimize.cpython-312.pyc\r\n",
      "dataset.cpython-312.pyc\t\t train.cpython-312.pyc\r\n",
      "features.cpython-312.pyc\t utils.cpython-312.pyc\r\n",
      "\r\n",
      "GAT/tests:\r\n",
      "test_cv.py\t  test_optimize.py  test_plotting.py   verify_plots.py\r\n",
      "test_features.py  test_pipeline.py  verify_metrics.py\r\n"
     ]
    }
   ],
   "source": [
    "# Wyświetla listę plików w pobranym folderze\n",
    "!ls -R  GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb7aea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:47:14.286762Z",
     "iopub.status.busy": "2025-12-05T19:47:14.286560Z",
     "iopub.status.idle": "2025-12-05T19:47:14.290675Z",
     "shell.execute_reply": "2025-12-05T19:47:14.290075Z"
    },
    "papermill": {
     "duration": 0.008101,
     "end_time": "2025-12-05T19:47:14.291672",
     "exception": false,
     "start_time": "2025-12-05T19:47:14.283571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktualny katalog: /kaggle/working/GAT\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "# 1. Zmiana katalogu roboczego (odpowiednik komendy 'cd')\n",
    "os.chdir('./GAT')\n",
    "print(f\"Aktualny katalog: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bc6b3d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-05T19:47:14.297650Z",
     "iopub.status.busy": "2025-12-05T19:47:14.297054Z",
     "iopub.status.idle": "2025-12-05T19:48:37.981189Z",
     "shell.execute_reply": "2025-12-05T19:48:37.980116Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 83.689192,
     "end_time": "2025-12-05T19:48:37.983093",
     "exception": false,
     "start_time": "2025-12-05T19:47:14.293901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "Instaluję dla: torch-260 + cu124\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\r\n",
      "Collecting pyg_lib\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.5.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_scatter\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_sparse\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_cluster\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_spline_conv\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\r\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\r\n",
      "Successfully installed pyg_lib-0.5.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\r\n",
      "Collecting torch-geometric>=2.3.0 (from -r requirements.txt (line 2))\r\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting rdkit>=2023.3.1 (from -r requirements.txt (line 3))\r\n",
      "  Downloading rdkit-2025.9.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.7.2)\r\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.12.2)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.2.2)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.5.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.13.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (7.1.3)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.32.5)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.6.0)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit>=2023.3.1->-r requirements.txt (line 3)) (11.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2.4.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (25.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (3.6.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->-r requirements.txt (line 10)) (1.17.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->-r requirements.txt (line 10)) (6.10.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->-r requirements.txt (line 10)) (2.0.41)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->-r requirements.txt (line 10)) (6.0.3)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->-r requirements.txt (line 10)) (1.3.10)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 4)) (1.17.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->-r requirements.txt (line 10)) (3.2.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.22.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2025.10.5)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rdkit-2025.9.3-cp311-cp311-manylinux_2_28_x86_64.whl (36.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-geometric, rdkit\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdkit-2025.9.3 torch-geometric-2.7.0\r\n"
     ]
    }
   ],
   "source": [
    "# Najpierw sprawdźmy wersję po restarcie (czasem GPU ma starszego PyTorcha)\n",
    "import torch\n",
    "version = torch.__version__\n",
    "print(f\"PyTorch version: {version}\")\n",
    "\n",
    "# Instalacja PyG i bibliotek pomocniczych (korzystamy z gotowych paczek .whl, żeby nie kompilować przez 20 min)\n",
    "# UWAGA: Ta komenda dynamicznie dobiera link do wersji Twojego PyTorcha\n",
    "torch_version_suffix = version.split('+')[0].replace('.', '') # np. 260 lub 240\n",
    "cuda_version_suffix = 'cu' + torch.version.cuda.replace('.', '') # np. cu121\n",
    "\n",
    "print(f\"Instaluję dla: torch-{torch_version_suffix} + {cuda_version_suffix}\")\n",
    "\n",
    "# Instalacja zależności\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
    "  -f https://data.pyg.org/whl/torch-{version}.html\n",
    "\n",
    "# Instalacja reszty z Twojego pliku (bez ponownego instalowania torch-geometric, bo zrobiliśmy to wyżej)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d04f6fd",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-05T19:48:38.049551Z",
     "iopub.status.busy": "2025-12-05T19:48:38.048958Z",
     "iopub.status.idle": "2025-12-05T19:48:49.619918Z",
     "shell.execute_reply": "2025-12-05T19:48:49.619147Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 11.610289,
     "end_time": "2025-12-05T19:48:49.621116",
     "exception": false,
     "start_time": "2025-12-05T19:48:38.010827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA dostępne: True\n",
      "Wersja PyTorch: 2.6.0+cu124\n",
      "Wersja PyG: 2.7.0\n",
      "✅ GATConv zaimportowany pomyślnie!\n",
      "✅ torch_scatter obecny\n",
      "✅ torch_sparse obecny\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(f\"CUDA dostępne: {torch.cuda.is_available()}\")\n",
    "print(f\"Wersja PyTorch: {torch.__version__}\")\n",
    "print(f\"Wersja PyG: {torch_geometric.__version__}\")\n",
    "\n",
    "# Próba importu kluczowych warstw\n",
    "try:\n",
    "    from torch_geometric.nn import GATConv\n",
    "    print(\"✅ GATConv zaimportowany pomyślnie!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Błąd importu GATConv: {e}\")\n",
    "\n",
    "# Sprawdzenie czy mamy backendy (scatter/sparse)\n",
    "# PyG 2.7+ potrafi czasem działać bez nich (wolniej), ale warto sprawdzić\n",
    "try:\n",
    "    import torch_scatter\n",
    "    print(\"✅ torch_scatter obecny\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ torch_scatter BRAK (Może to spowolnić trening lub wywołać błąd)\")\n",
    "\n",
    "try:\n",
    "    import torch_sparse\n",
    "    print(\"✅ torch_sparse obecny\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ torch_sparse BRAK (Wymagany dla niektórych operatorów)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b58c335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:48:49.668695Z",
     "iopub.status.busy": "2025-12-05T19:48:49.667967Z",
     "iopub.status.idle": "2025-12-05T19:48:49.671534Z",
     "shell.execute_reply": "2025-12-05T19:48:49.670818Z"
    },
    "papermill": {
     "duration": 0.028636,
     "end_time": "2025-12-05T19:48:49.672578",
     "exception": false,
     "start_time": "2025-12-05T19:48:49.643942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python main.py --raw_file /kaggle/input/bindingdb-smiles/BindingDB_All.tsv --processed_dir ./data/processed --cv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45163434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:48:49.717958Z",
     "iopub.status.busy": "2025-12-05T19:48:49.717695Z",
     "iopub.status.idle": "2025-12-05T21:33:49.833416Z",
     "shell.execute_reply": "2025-12-05T21:33:49.832631Z"
    },
    "papermill": {
     "duration": 6300.139891,
     "end_time": "2025-12-05T21:33:49.834993",
     "exception": false,
     "start_time": "2025-12-05T19:48:49.695102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GAT BRD4 Binding Prediction Pipeline...\r\n",
      "Loading and filtering data from /kaggle/input/bindingdb-smiles/BindingDB_All.tsv in chunks of 100000...\r\n",
      "Processed 1000000 rows...\r\n",
      "Processed 2000000 rows...\r\n",
      "Processed 3000000 rows...\r\n",
      "Finished processing 3078912 rows.\r\n",
      "Found 22758 records for BRD4.\r\n",
      "Cleaning and Labeling...\r\n",
      "Final dataset size: 22616\r\n",
      "Creating Graph Dataset in ./data/processed (this may take a while)...\r\n",
      "Processing...\r\n",
      "Processing Molecules:  11%|█▋             | 2583/22616 [00:03<00:26, 751.76it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 18 19 23\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 23 24 28\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 20 21 25\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 20 21 25\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "Processing Molecules:  12%|█▊             | 2676/22616 [00:03<00:24, 803.74it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 5\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 5\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 20 21 23\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 3 4 5\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 3 4 5\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 20 21 23\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  12%|█▊             | 2776/22616 [00:04<00:23, 861.42it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 36 37 39\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 36 37 39\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 29 30 32\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 29 30 32\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 31 32 34\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 31 32 34\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  13%|█▉             | 2863/22616 [00:04<00:23, 831.60it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 28 29 31\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 28 29 31\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  13%|█▉             | 2947/22616 [00:04<00:25, 775.97it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 23 24 27\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 23 24 27\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "Processing Molecules:  13%|██             | 3026/22616 [00:04<00:26, 749.85it/s][19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 2 4 7\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 2 4 7\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:44] Explicit valence for atom # 3 F, 3, is greater than permitted\r\n",
      "Processing Molecules:  17%|██▌            | 3771/22616 [00:05<00:28, 671.35it/s][19:52:45] Explicit valence for atom # 23 N, 4, is greater than permitted\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 34 35 38\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 34 35 38\r\n",
      "[19:52:45] Explicit valence for atom # 4 N, 4, is greater than permitted\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "Processing Molecules:  17%|██▌            | 3839/22616 [00:05<00:29, 647.48it/s][19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:45] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  19%|██▊            | 4186/22616 [00:06<00:30, 596.00it/s][19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  19%|██▊            | 4246/22616 [00:06<00:30, 596.86it/s][19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 30 31 33\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 30 31 33\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[19:52:46] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  23%|███▍           | 5222/22616 [00:07<00:22, 766.42it/s][19:52:47] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[19:52:47] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[19:52:47] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[19:52:47] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  25%|███▋           | 5613/22616 [00:08<00:22, 772.13it/s][19:52:48] Explicit valence for atom # 12 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  26%|███▉           | 5943/22616 [00:08<00:22, 729.88it/s][19:52:48] Explicit valence for atom # 6 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  35%|█████▏         | 7806/22616 [00:11<00:21, 703.99it/s][19:52:51] Can't kekulize mol.  Unkekulized atoms: 26 27 28 29 31\r\n",
      "[19:52:51] Can't kekulize mol.  Unkekulized atoms: 26 27 28 29 31\r\n",
      "Processing Molecules: 100%|██████████████| 22616/22616 [00:33<00:00, 672.68it/s]\r\n",
      "Processing complete. Successfully processed: 22421. Failed: 195.\r\n",
      "Done!\r\n",
      "Starting Hyperparameter Optimization with 15 trials...\r\n",
      "\u001b[32m[I 2025-12-05 19:53:14,930]\u001b[0m A new study created in memory with name: no-name-673e557d-6553-4e9a-b39d-23b8aff7a6ae\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3136, Val AP: 0.8395, Val AUC: 0.7549\r\n",
      "Epoch: 002, Loss: 0.2920, Val AP: 0.8616, Val AUC: 0.7824\r\n",
      "Epoch: 003, Loss: 0.2831, Val AP: 0.8723, Val AUC: 0.7982\r\n",
      "Epoch: 004, Loss: 0.2760, Val AP: 0.8761, Val AUC: 0.8008\r\n",
      "Epoch: 005, Loss: 0.2729, Val AP: 0.8883, Val AUC: 0.8088\r\n",
      "Epoch: 006, Loss: 0.2689, Val AP: 0.8948, Val AUC: 0.8173\r\n",
      "Epoch: 007, Loss: 0.2652, Val AP: 0.8956, Val AUC: 0.8212\r\n",
      "Epoch: 008, Loss: 0.2598, Val AP: 0.8937, Val AUC: 0.8169\r\n",
      "Epoch: 009, Loss: 0.2577, Val AP: 0.8987, Val AUC: 0.8226\r\n",
      "Epoch: 010, Loss: 0.2563, Val AP: 0.9002, Val AUC: 0.8262\r\n",
      "Epoch: 011, Loss: 0.2551, Val AP: 0.8983, Val AUC: 0.8223\r\n",
      "Epoch: 012, Loss: 0.2545, Val AP: 0.8995, Val AUC: 0.8255\r\n",
      "Epoch: 013, Loss: 0.2531, Val AP: 0.8986, Val AUC: 0.8227\r\n",
      "Epoch: 014, Loss: 0.2524, Val AP: 0.9038, Val AUC: 0.8329\r\n",
      "Epoch: 015, Loss: 0.2531, Val AP: 0.9038, Val AUC: 0.8287\r\n",
      "Epoch: 016, Loss: 0.2523, Val AP: 0.9033, Val AUC: 0.8308\r\n",
      "Epoch: 017, Loss: 0.2537, Val AP: 0.8928, Val AUC: 0.8141\r\n",
      "Epoch: 018, Loss: 0.2507, Val AP: 0.9055, Val AUC: 0.8322\r\n",
      "Epoch: 019, Loss: 0.2519, Val AP: 0.9035, Val AUC: 0.8305\r\n",
      "Epoch: 020, Loss: 0.2503, Val AP: 0.9055, Val AUC: 0.8340\r\n",
      "Epoch: 021, Loss: 0.2496, Val AP: 0.9088, Val AUC: 0.8387\r\n",
      "Epoch: 022, Loss: 0.2494, Val AP: 0.8958, Val AUC: 0.8217\r\n",
      "Epoch: 023, Loss: 0.2496, Val AP: 0.9078, Val AUC: 0.8373\r\n",
      "Epoch: 024, Loss: 0.2482, Val AP: 0.9002, Val AUC: 0.8240\r\n",
      "Epoch: 025, Loss: 0.2498, Val AP: 0.9094, Val AUC: 0.8390\r\n",
      "Epoch: 026, Loss: 0.2502, Val AP: 0.9065, Val AUC: 0.8357\r\n",
      "Epoch: 027, Loss: 0.2498, Val AP: 0.9042, Val AUC: 0.8310\r\n",
      "Epoch: 028, Loss: 0.2479, Val AP: 0.9090, Val AUC: 0.8347\r\n",
      "Epoch: 029, Loss: 0.2467, Val AP: 0.9025, Val AUC: 0.8300\r\n",
      "Epoch: 030, Loss: 0.2484, Val AP: 0.9091, Val AUC: 0.8406\r\n",
      "Epoch: 031, Loss: 0.2475, Val AP: 0.9097, Val AUC: 0.8408\r\n",
      "Epoch: 032, Loss: 0.2461, Val AP: 0.9088, Val AUC: 0.8417\r\n",
      "Epoch: 033, Loss: 0.2463, Val AP: 0.9082, Val AUC: 0.8360\r\n",
      "Epoch: 034, Loss: 0.2450, Val AP: 0.9010, Val AUC: 0.8287\r\n",
      "Epoch: 035, Loss: 0.2447, Val AP: 0.9134, Val AUC: 0.8446\r\n",
      "Epoch: 036, Loss: 0.2429, Val AP: 0.9101, Val AUC: 0.8423\r\n",
      "Epoch: 037, Loss: 0.2421, Val AP: 0.9092, Val AUC: 0.8385\r\n",
      "Epoch: 038, Loss: 0.2431, Val AP: 0.9147, Val AUC: 0.8461\r\n",
      "Epoch: 039, Loss: 0.2430, Val AP: 0.9162, Val AUC: 0.8508\r\n",
      "Epoch: 040, Loss: 0.2423, Val AP: 0.9134, Val AUC: 0.8482\r\n",
      "Epoch: 041, Loss: 0.2423, Val AP: 0.9195, Val AUC: 0.8559\r\n",
      "Epoch: 042, Loss: 0.2403, Val AP: 0.9169, Val AUC: 0.8523\r\n",
      "Epoch: 043, Loss: 0.2427, Val AP: 0.9168, Val AUC: 0.8529\r\n",
      "Epoch: 044, Loss: 0.2399, Val AP: 0.9049, Val AUC: 0.8319\r\n",
      "Epoch: 045, Loss: 0.2414, Val AP: 0.9162, Val AUC: 0.8501\r\n",
      "Epoch: 046, Loss: 0.2398, Val AP: 0.9191, Val AUC: 0.8535\r\n",
      "Epoch: 047, Loss: 0.2386, Val AP: 0.9165, Val AUC: 0.8522\r\n",
      "Epoch: 048, Loss: 0.2393, Val AP: 0.9029, Val AUC: 0.8276\r\n",
      "Epoch: 049, Loss: 0.2385, Val AP: 0.9182, Val AUC: 0.8529\r\n",
      "Epoch: 050, Loss: 0.2411, Val AP: 0.9110, Val AUC: 0.8405\r\n",
      "Epoch: 051, Loss: 0.2410, Val AP: 0.9146, Val AUC: 0.8480\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.855917123335861, 'AP': 0.9195372694089661, 'F1': 0.8120041393583994, 'F0.5': 0.8674823113207548}\r\n",
      "\u001b[32m[I 2025-12-05 19:57:56,478]\u001b[0m Trial 0 finished with value: 0.9195372694089661 and parameters: {'hidden_dim': 64, 'heads': 2, 'layers': 2, 'dropout': 0.3258815300205407, 'lr': 0.0017768337261110873}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3249, Val AP: 0.8272, Val AUC: 0.7426\r\n",
      "Epoch: 002, Loss: 0.2973, Val AP: 0.8455, Val AUC: 0.7638\r\n",
      "Epoch: 003, Loss: 0.2913, Val AP: 0.8538, Val AUC: 0.7701\r\n",
      "Epoch: 004, Loss: 0.2886, Val AP: 0.8588, Val AUC: 0.7748\r\n",
      "Epoch: 005, Loss: 0.2854, Val AP: 0.8674, Val AUC: 0.7820\r\n",
      "Epoch: 006, Loss: 0.2827, Val AP: 0.8696, Val AUC: 0.7832\r\n",
      "Epoch: 007, Loss: 0.2797, Val AP: 0.8807, Val AUC: 0.7939\r\n",
      "Epoch: 008, Loss: 0.2764, Val AP: 0.8828, Val AUC: 0.7989\r\n",
      "Epoch: 009, Loss: 0.2740, Val AP: 0.8874, Val AUC: 0.7998\r\n",
      "Epoch: 010, Loss: 0.2708, Val AP: 0.8875, Val AUC: 0.8031\r\n",
      "Epoch: 011, Loss: 0.2696, Val AP: 0.8882, Val AUC: 0.8052\r\n",
      "Epoch: 012, Loss: 0.2675, Val AP: 0.8941, Val AUC: 0.8073\r\n",
      "Epoch: 013, Loss: 0.2644, Val AP: 0.8874, Val AUC: 0.8095\r\n",
      "Epoch: 014, Loss: 0.2627, Val AP: 0.8941, Val AUC: 0.8134\r\n",
      "Epoch: 015, Loss: 0.2618, Val AP: 0.8968, Val AUC: 0.8147\r\n",
      "Epoch: 016, Loss: 0.2620, Val AP: 0.8960, Val AUC: 0.8169\r\n",
      "Epoch: 017, Loss: 0.2581, Val AP: 0.8975, Val AUC: 0.8205\r\n",
      "Epoch: 018, Loss: 0.2589, Val AP: 0.8979, Val AUC: 0.8207\r\n",
      "Epoch: 019, Loss: 0.2587, Val AP: 0.8980, Val AUC: 0.8206\r\n",
      "Epoch: 020, Loss: 0.2565, Val AP: 0.8988, Val AUC: 0.8200\r\n",
      "Epoch: 021, Loss: 0.2541, Val AP: 0.9005, Val AUC: 0.8242\r\n",
      "Epoch: 022, Loss: 0.2540, Val AP: 0.9017, Val AUC: 0.8262\r\n",
      "Epoch: 023, Loss: 0.2522, Val AP: 0.9032, Val AUC: 0.8274\r\n",
      "Epoch: 024, Loss: 0.2516, Val AP: 0.9044, Val AUC: 0.8318\r\n",
      "Epoch: 025, Loss: 0.2505, Val AP: 0.9043, Val AUC: 0.8307\r\n",
      "Epoch: 026, Loss: 0.2495, Val AP: 0.9046, Val AUC: 0.8302\r\n",
      "Epoch: 027, Loss: 0.2485, Val AP: 0.9056, Val AUC: 0.8338\r\n",
      "Epoch: 028, Loss: 0.2494, Val AP: 0.9035, Val AUC: 0.8322\r\n",
      "Epoch: 029, Loss: 0.2475, Val AP: 0.9032, Val AUC: 0.8314\r\n",
      "Epoch: 030, Loss: 0.2469, Val AP: 0.9034, Val AUC: 0.8327\r\n",
      "Epoch: 031, Loss: 0.2456, Val AP: 0.9023, Val AUC: 0.8318\r\n",
      "Epoch: 032, Loss: 0.2478, Val AP: 0.9051, Val AUC: 0.8324\r\n",
      "Epoch: 033, Loss: 0.2460, Val AP: 0.9048, Val AUC: 0.8365\r\n",
      "Epoch: 034, Loss: 0.2467, Val AP: 0.9057, Val AUC: 0.8355\r\n",
      "Epoch: 035, Loss: 0.2466, Val AP: 0.9043, Val AUC: 0.8333\r\n",
      "Epoch: 036, Loss: 0.2439, Val AP: 0.9041, Val AUC: 0.8335\r\n",
      "Epoch: 037, Loss: 0.2442, Val AP: 0.9030, Val AUC: 0.8334\r\n",
      "Epoch: 038, Loss: 0.2436, Val AP: 0.9062, Val AUC: 0.8377\r\n",
      "Epoch: 039, Loss: 0.2432, Val AP: 0.9028, Val AUC: 0.8337\r\n",
      "Epoch: 040, Loss: 0.2434, Val AP: 0.9058, Val AUC: 0.8372\r\n",
      "Epoch: 041, Loss: 0.2435, Val AP: 0.9046, Val AUC: 0.8370\r\n",
      "Epoch: 042, Loss: 0.2416, Val AP: 0.9064, Val AUC: 0.8403\r\n",
      "Epoch: 043, Loss: 0.2415, Val AP: 0.9072, Val AUC: 0.8382\r\n",
      "Epoch: 044, Loss: 0.2409, Val AP: 0.9052, Val AUC: 0.8381\r\n",
      "Epoch: 045, Loss: 0.2420, Val AP: 0.9076, Val AUC: 0.8402\r\n",
      "Epoch: 046, Loss: 0.2413, Val AP: 0.8992, Val AUC: 0.8316\r\n",
      "Epoch: 047, Loss: 0.2408, Val AP: 0.9109, Val AUC: 0.8433\r\n",
      "Epoch: 048, Loss: 0.2419, Val AP: 0.9076, Val AUC: 0.8406\r\n",
      "Epoch: 049, Loss: 0.2407, Val AP: 0.9073, Val AUC: 0.8424\r\n",
      "Epoch: 050, Loss: 0.2405, Val AP: 0.9088, Val AUC: 0.8433\r\n",
      "Epoch: 051, Loss: 0.2405, Val AP: 0.9082, Val AUC: 0.8438\r\n",
      "Epoch: 052, Loss: 0.2413, Val AP: 0.9037, Val AUC: 0.8355\r\n",
      "Epoch: 053, Loss: 0.2400, Val AP: 0.9081, Val AUC: 0.8424\r\n",
      "Epoch: 054, Loss: 0.2391, Val AP: 0.9003, Val AUC: 0.8352\r\n",
      "Epoch: 055, Loss: 0.2394, Val AP: 0.9065, Val AUC: 0.8414\r\n",
      "Epoch: 056, Loss: 0.2387, Val AP: 0.9079, Val AUC: 0.8408\r\n",
      "Epoch: 057, Loss: 0.2386, Val AP: 0.9050, Val AUC: 0.8395\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8432719142582417, 'AP': 0.9109045225547445, 'F1': 0.83984375, 'F0.5': 0.8627608346709471}\r\n",
      "\u001b[32m[I 2025-12-05 20:04:09,159]\u001b[0m Trial 1 finished with value: 0.9109045225547445 and parameters: {'hidden_dim': 32, 'heads': 8, 'layers': 3, 'dropout': 0.2559747365292689, 'lr': 0.00023610012349050715}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3572, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 002, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 003, Loss: 0.3533, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 004, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 005, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 006, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 007, Loss: 0.3535, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 008, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 009, Loss: 0.3535, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 010, Loss: 0.3534, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 011, Loss: 0.3535, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.5, 'AP': 0.7154326494201606, 'F1': 0.0, 'F0.5': 0.0}\r\n",
      "\u001b[32m[I 2025-12-05 20:05:32,637]\u001b[0m Trial 2 finished with value: 0.7154326494201606 and parameters: {'hidden_dim': 128, 'heads': 4, 'layers': 3, 'dropout': 0.23762134478408614, 'lr': 0.0068946823521610304}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3113, Val AP: 0.8320, Val AUC: 0.7410\r\n",
      "Epoch: 002, Loss: 0.2904, Val AP: 0.8623, Val AUC: 0.7759\r\n",
      "Epoch: 003, Loss: 0.2806, Val AP: 0.8734, Val AUC: 0.7930\r\n",
      "Epoch: 004, Loss: 0.2712, Val AP: 0.8870, Val AUC: 0.8100\r\n",
      "Epoch: 005, Loss: 0.2646, Val AP: 0.8964, Val AUC: 0.8214\r\n",
      "Epoch: 006, Loss: 0.2624, Val AP: 0.9009, Val AUC: 0.8245\r\n",
      "Epoch: 007, Loss: 0.2582, Val AP: 0.8976, Val AUC: 0.8241\r\n",
      "Epoch: 008, Loss: 0.2591, Val AP: 0.8998, Val AUC: 0.8248\r\n",
      "Epoch: 009, Loss: 0.2556, Val AP: 0.8953, Val AUC: 0.8194\r\n",
      "Epoch: 010, Loss: 0.2536, Val AP: 0.8972, Val AUC: 0.8221\r\n",
      "Epoch: 011, Loss: 0.2526, Val AP: 0.8971, Val AUC: 0.8227\r\n",
      "Epoch: 012, Loss: 0.2532, Val AP: 0.8990, Val AUC: 0.8254\r\n",
      "Epoch: 013, Loss: 0.2507, Val AP: 0.9048, Val AUC: 0.8306\r\n",
      "Epoch: 014, Loss: 0.2504, Val AP: 0.9049, Val AUC: 0.8324\r\n",
      "Epoch: 015, Loss: 0.2504, Val AP: 0.9056, Val AUC: 0.8340\r\n",
      "Epoch: 016, Loss: 0.2486, Val AP: 0.9106, Val AUC: 0.8414\r\n",
      "Epoch: 017, Loss: 0.2475, Val AP: 0.9089, Val AUC: 0.8386\r\n",
      "Epoch: 018, Loss: 0.2467, Val AP: 0.9110, Val AUC: 0.8402\r\n",
      "Epoch: 019, Loss: 0.2467, Val AP: 0.9078, Val AUC: 0.8377\r\n",
      "Epoch: 020, Loss: 0.2462, Val AP: 0.9036, Val AUC: 0.8354\r\n",
      "Epoch: 021, Loss: 0.2457, Val AP: 0.9095, Val AUC: 0.8402\r\n",
      "Epoch: 022, Loss: 0.2422, Val AP: 0.9074, Val AUC: 0.8375\r\n",
      "Epoch: 023, Loss: 0.2449, Val AP: 0.9029, Val AUC: 0.8322\r\n",
      "Epoch: 024, Loss: 0.2426, Val AP: 0.9042, Val AUC: 0.8376\r\n",
      "Epoch: 025, Loss: 0.2415, Val AP: 0.9103, Val AUC: 0.8417\r\n",
      "Epoch: 026, Loss: 0.2429, Val AP: 0.9086, Val AUC: 0.8386\r\n",
      "Epoch: 027, Loss: 0.2451, Val AP: 0.9037, Val AUC: 0.8344\r\n",
      "Epoch: 028, Loss: 0.2430, Val AP: 0.9083, Val AUC: 0.8407\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8402074750428006, 'AP': 0.9110386326962792, 'F1': 0.7064185339916446, 'F0.5': 0.8129370629370629}\r\n",
      "\u001b[32m[I 2025-12-05 20:08:07,904]\u001b[0m Trial 3 finished with value: 0.9110386326962792 and parameters: {'hidden_dim': 128, 'heads': 2, 'layers': 2, 'dropout': 0.3691844191955861, 'lr': 0.0006330107800668406}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3087, Val AP: 0.8380, Val AUC: 0.7493\r\n",
      "Epoch: 002, Loss: 0.2890, Val AP: 0.8455, Val AUC: 0.7623\r\n",
      "Epoch: 003, Loss: 0.2817, Val AP: 0.8665, Val AUC: 0.7839\r\n",
      "Epoch: 004, Loss: 0.2746, Val AP: 0.8776, Val AUC: 0.7876\r\n",
      "Epoch: 005, Loss: 0.2675, Val AP: 0.8857, Val AUC: 0.8061\r\n",
      "Epoch: 006, Loss: 0.2628, Val AP: 0.8900, Val AUC: 0.8096\r\n",
      "Epoch: 007, Loss: 0.2630, Val AP: 0.8885, Val AUC: 0.8094\r\n",
      "Epoch: 008, Loss: 0.2627, Val AP: 0.8925, Val AUC: 0.8152\r\n",
      "Epoch: 009, Loss: 0.2589, Val AP: 0.8889, Val AUC: 0.8035\r\n",
      "Epoch: 010, Loss: 0.2581, Val AP: 0.8959, Val AUC: 0.8196\r\n",
      "Epoch: 011, Loss: 0.2568, Val AP: 0.8980, Val AUC: 0.8217\r\n",
      "Epoch: 012, Loss: 0.2554, Val AP: 0.8982, Val AUC: 0.8203\r\n",
      "Epoch: 013, Loss: 0.2558, Val AP: 0.9009, Val AUC: 0.8271\r\n",
      "Epoch: 014, Loss: 0.2539, Val AP: 0.9017, Val AUC: 0.8279\r\n",
      "Epoch: 015, Loss: 0.2514, Val AP: 0.9060, Val AUC: 0.8323\r\n",
      "Epoch: 016, Loss: 0.2509, Val AP: 0.8950, Val AUC: 0.8184\r\n",
      "Epoch: 017, Loss: 0.2485, Val AP: 0.8954, Val AUC: 0.8183\r\n",
      "Epoch: 018, Loss: 0.2488, Val AP: 0.9062, Val AUC: 0.8300\r\n",
      "Epoch: 019, Loss: 0.2461, Val AP: 0.9089, Val AUC: 0.8345\r\n",
      "Epoch: 020, Loss: 0.2459, Val AP: 0.9107, Val AUC: 0.8364\r\n",
      "Epoch: 021, Loss: 0.2463, Val AP: 0.9060, Val AUC: 0.8298\r\n",
      "Epoch: 022, Loss: 0.2454, Val AP: 0.9049, Val AUC: 0.8272\r\n",
      "Epoch: 023, Loss: 0.2444, Val AP: 0.9075, Val AUC: 0.8331\r\n",
      "Epoch: 024, Loss: 0.2445, Val AP: 0.9105, Val AUC: 0.8336\r\n",
      "Epoch: 025, Loss: 0.2420, Val AP: 0.9080, Val AUC: 0.8357\r\n",
      "Epoch: 026, Loss: 0.2427, Val AP: 0.9097, Val AUC: 0.8346\r\n",
      "Epoch: 027, Loss: 0.2418, Val AP: 0.9133, Val AUC: 0.8357\r\n",
      "Epoch: 028, Loss: 0.2409, Val AP: 0.9145, Val AUC: 0.8381\r\n",
      "Epoch: 029, Loss: 0.2391, Val AP: 0.9155, Val AUC: 0.8398\r\n",
      "Epoch: 030, Loss: 0.2377, Val AP: 0.9111, Val AUC: 0.8373\r\n",
      "Epoch: 031, Loss: 0.2387, Val AP: 0.9135, Val AUC: 0.8383\r\n",
      "Epoch: 032, Loss: 0.2372, Val AP: 0.9147, Val AUC: 0.8399\r\n",
      "Epoch: 033, Loss: 0.2383, Val AP: 0.8992, Val AUC: 0.8267\r\n",
      "Epoch: 034, Loss: 0.2373, Val AP: 0.9169, Val AUC: 0.8471\r\n",
      "Epoch: 035, Loss: 0.2348, Val AP: 0.9063, Val AUC: 0.8331\r\n",
      "Epoch: 036, Loss: 0.2359, Val AP: 0.9079, Val AUC: 0.8338\r\n",
      "Epoch: 037, Loss: 0.2359, Val AP: 0.9072, Val AUC: 0.8341\r\n",
      "Epoch: 038, Loss: 0.2340, Val AP: 0.9109, Val AUC: 0.8356\r\n",
      "Epoch: 039, Loss: 0.2359, Val AP: 0.9161, Val AUC: 0.8469\r\n",
      "Epoch: 040, Loss: 0.2354, Val AP: 0.9090, Val AUC: 0.8406\r\n",
      "Epoch: 041, Loss: 0.2333, Val AP: 0.9105, Val AUC: 0.8371\r\n",
      "Epoch: 042, Loss: 0.2336, Val AP: 0.8905, Val AUC: 0.8176\r\n",
      "Epoch: 043, Loss: 0.2329, Val AP: 0.9133, Val AUC: 0.8386\r\n",
      "Epoch: 044, Loss: 0.2349, Val AP: 0.9133, Val AUC: 0.8429\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8470770565748638, 'AP': 0.916949501272205, 'F1': 0.8732568949488689, 'F0.5': 0.8701828063241107}\r\n",
      "\u001b[32m[I 2025-12-05 20:12:57,989]\u001b[0m Trial 4 finished with value: 0.916949501272205 and parameters: {'hidden_dim': 64, 'heads': 4, 'layers': 3, 'dropout': 0.26124124991903536, 'lr': 0.0007667897643121597}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3173, Val AP: 0.8234, Val AUC: 0.7349\r\n",
      "Epoch: 002, Loss: 0.2956, Val AP: 0.8477, Val AUC: 0.7586\r\n",
      "Epoch: 003, Loss: 0.2886, Val AP: 0.8632, Val AUC: 0.7714\r\n",
      "Epoch: 004, Loss: 0.2823, Val AP: 0.8750, Val AUC: 0.7818\r\n",
      "Epoch: 005, Loss: 0.2749, Val AP: 0.8858, Val AUC: 0.7990\r\n",
      "Epoch: 006, Loss: 0.2699, Val AP: 0.8815, Val AUC: 0.8001\r\n",
      "Epoch: 007, Loss: 0.2670, Val AP: 0.8969, Val AUC: 0.8130\r\n",
      "Epoch: 008, Loss: 0.2646, Val AP: 0.8966, Val AUC: 0.8155\r\n",
      "Epoch: 009, Loss: 0.2608, Val AP: 0.8985, Val AUC: 0.8201\r\n",
      "Epoch: 010, Loss: 0.2599, Val AP: 0.8985, Val AUC: 0.8205\r\n",
      "Epoch: 011, Loss: 0.2591, Val AP: 0.8956, Val AUC: 0.8179\r\n",
      "Epoch: 012, Loss: 0.2577, Val AP: 0.9005, Val AUC: 0.8236\r\n",
      "Epoch: 013, Loss: 0.2561, Val AP: 0.8993, Val AUC: 0.8232\r\n",
      "Epoch: 014, Loss: 0.2559, Val AP: 0.9020, Val AUC: 0.8263\r\n",
      "Epoch: 015, Loss: 0.2540, Val AP: 0.9018, Val AUC: 0.8269\r\n",
      "Epoch: 016, Loss: 0.2531, Val AP: 0.9048, Val AUC: 0.8309\r\n",
      "Epoch: 017, Loss: 0.2524, Val AP: 0.9048, Val AUC: 0.8318\r\n",
      "Epoch: 018, Loss: 0.2512, Val AP: 0.9054, Val AUC: 0.8310\r\n",
      "Epoch: 019, Loss: 0.2491, Val AP: 0.9048, Val AUC: 0.8327\r\n",
      "Epoch: 020, Loss: 0.2475, Val AP: 0.9034, Val AUC: 0.8319\r\n",
      "Epoch: 021, Loss: 0.2465, Val AP: 0.9111, Val AUC: 0.8395\r\n",
      "Epoch: 022, Loss: 0.2452, Val AP: 0.9105, Val AUC: 0.8409\r\n",
      "Epoch: 023, Loss: 0.2429, Val AP: 0.9123, Val AUC: 0.8442\r\n",
      "Epoch: 024, Loss: 0.2437, Val AP: 0.9140, Val AUC: 0.8486\r\n",
      "Epoch: 025, Loss: 0.2421, Val AP: 0.9134, Val AUC: 0.8462\r\n",
      "Epoch: 026, Loss: 0.2399, Val AP: 0.9131, Val AUC: 0.8472\r\n",
      "Epoch: 027, Loss: 0.2382, Val AP: 0.9136, Val AUC: 0.8479\r\n",
      "Epoch: 028, Loss: 0.2384, Val AP: 0.9114, Val AUC: 0.8473\r\n",
      "Epoch: 029, Loss: 0.2373, Val AP: 0.9121, Val AUC: 0.8479\r\n",
      "Epoch: 030, Loss: 0.2382, Val AP: 0.9129, Val AUC: 0.8497\r\n",
      "Epoch: 031, Loss: 0.2358, Val AP: 0.9153, Val AUC: 0.8529\r\n",
      "Epoch: 032, Loss: 0.2353, Val AP: 0.9143, Val AUC: 0.8536\r\n",
      "Epoch: 033, Loss: 0.2355, Val AP: 0.9133, Val AUC: 0.8547\r\n",
      "Epoch: 034, Loss: 0.2344, Val AP: 0.9132, Val AUC: 0.8535\r\n",
      "Epoch: 035, Loss: 0.2346, Val AP: 0.9126, Val AUC: 0.8538\r\n",
      "Epoch: 036, Loss: 0.2339, Val AP: 0.9149, Val AUC: 0.8572\r\n",
      "Epoch: 037, Loss: 0.2340, Val AP: 0.9144, Val AUC: 0.8560\r\n",
      "Epoch: 038, Loss: 0.2337, Val AP: 0.9079, Val AUC: 0.8505\r\n",
      "Epoch: 039, Loss: 0.2332, Val AP: 0.9123, Val AUC: 0.8557\r\n",
      "Epoch: 040, Loss: 0.2338, Val AP: 0.9125, Val AUC: 0.8550\r\n",
      "Epoch: 041, Loss: 0.2324, Val AP: 0.9129, Val AUC: 0.8546\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8528824881370243, 'AP': 0.9152635592534126, 'F1': 0.728978978978979, 'F0.5': 0.8307665982203969}\r\n",
      "\u001b[32m[I 2025-12-05 20:16:39,742]\u001b[0m Trial 5 finished with value: 0.9152635592534126 and parameters: {'hidden_dim': 64, 'heads': 4, 'layers': 2, 'dropout': 0.1874306964738818, 'lr': 0.0003468152092879464}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3120, Val AP: 0.8351, Val AUC: 0.7525\r\n",
      "Epoch: 002, Loss: 0.2875, Val AP: 0.8479, Val AUC: 0.7636\r\n",
      "Epoch: 003, Loss: 0.2798, Val AP: 0.8729, Val AUC: 0.7852\r\n",
      "Epoch: 004, Loss: 0.2715, Val AP: 0.8900, Val AUC: 0.8036\r\n",
      "Epoch: 005, Loss: 0.2665, Val AP: 0.8943, Val AUC: 0.8075\r\n",
      "Epoch: 006, Loss: 0.2615, Val AP: 0.8931, Val AUC: 0.8109\r\n",
      "Epoch: 007, Loss: 0.2569, Val AP: 0.8998, Val AUC: 0.8215\r\n",
      "Epoch: 008, Loss: 0.2545, Val AP: 0.9020, Val AUC: 0.8242\r\n",
      "Epoch: 009, Loss: 0.2526, Val AP: 0.9034, Val AUC: 0.8245\r\n",
      "Epoch: 010, Loss: 0.2526, Val AP: 0.9026, Val AUC: 0.8240\r\n",
      "Epoch: 011, Loss: 0.2492, Val AP: 0.9040, Val AUC: 0.8280\r\n",
      "Epoch: 012, Loss: 0.2478, Val AP: 0.9037, Val AUC: 0.8273\r\n",
      "Epoch: 013, Loss: 0.2461, Val AP: 0.9079, Val AUC: 0.8333\r\n",
      "Epoch: 014, Loss: 0.2450, Val AP: 0.9044, Val AUC: 0.8285\r\n",
      "Epoch: 015, Loss: 0.2457, Val AP: 0.9047, Val AUC: 0.8297\r\n",
      "Epoch: 016, Loss: 0.2415, Val AP: 0.9072, Val AUC: 0.8323\r\n",
      "Epoch: 017, Loss: 0.2408, Val AP: 0.9097, Val AUC: 0.8343\r\n",
      "Epoch: 018, Loss: 0.2396, Val AP: 0.9064, Val AUC: 0.8340\r\n",
      "Epoch: 019, Loss: 0.2383, Val AP: 0.9100, Val AUC: 0.8367\r\n",
      "Epoch: 020, Loss: 0.2381, Val AP: 0.9081, Val AUC: 0.8382\r\n",
      "Epoch: 021, Loss: 0.2363, Val AP: 0.9095, Val AUC: 0.8396\r\n",
      "Epoch: 022, Loss: 0.2363, Val AP: 0.9093, Val AUC: 0.8390\r\n",
      "Epoch: 023, Loss: 0.2350, Val AP: 0.9117, Val AUC: 0.8429\r\n",
      "Epoch: 024, Loss: 0.2339, Val AP: 0.9100, Val AUC: 0.8400\r\n",
      "Epoch: 025, Loss: 0.2336, Val AP: 0.9091, Val AUC: 0.8399\r\n",
      "Epoch: 026, Loss: 0.2313, Val AP: 0.9119, Val AUC: 0.8398\r\n",
      "Epoch: 027, Loss: 0.2325, Val AP: 0.9095, Val AUC: 0.8429\r\n",
      "Epoch: 028, Loss: 0.2317, Val AP: 0.9091, Val AUC: 0.8417\r\n",
      "Epoch: 029, Loss: 0.2298, Val AP: 0.9131, Val AUC: 0.8481\r\n",
      "Epoch: 030, Loss: 0.2283, Val AP: 0.9129, Val AUC: 0.8500\r\n",
      "Epoch: 031, Loss: 0.2268, Val AP: 0.9148, Val AUC: 0.8540\r\n",
      "Epoch: 032, Loss: 0.2255, Val AP: 0.9143, Val AUC: 0.8513\r\n",
      "Epoch: 033, Loss: 0.2229, Val AP: 0.9086, Val AUC: 0.8477\r\n",
      "Epoch: 034, Loss: 0.2243, Val AP: 0.9128, Val AUC: 0.8507\r\n",
      "Epoch: 035, Loss: 0.2234, Val AP: 0.9158, Val AUC: 0.8549\r\n",
      "Epoch: 036, Loss: 0.2231, Val AP: 0.9082, Val AUC: 0.8465\r\n",
      "Epoch: 037, Loss: 0.2217, Val AP: 0.9071, Val AUC: 0.8443\r\n",
      "Epoch: 038, Loss: 0.2213, Val AP: 0.9161, Val AUC: 0.8541\r\n",
      "Epoch: 039, Loss: 0.2213, Val AP: 0.9119, Val AUC: 0.8488\r\n",
      "Epoch: 040, Loss: 0.2202, Val AP: 0.9143, Val AUC: 0.8536\r\n",
      "Epoch: 041, Loss: 0.2195, Val AP: 0.9135, Val AUC: 0.8529\r\n",
      "Epoch: 042, Loss: 0.2197, Val AP: 0.9077, Val AUC: 0.8490\r\n",
      "Epoch: 043, Loss: 0.2192, Val AP: 0.9131, Val AUC: 0.8475\r\n",
      "Epoch: 044, Loss: 0.2201, Val AP: 0.9151, Val AUC: 0.8547\r\n",
      "Epoch: 045, Loss: 0.2193, Val AP: 0.9100, Val AUC: 0.8486\r\n",
      "Epoch: 046, Loss: 0.2187, Val AP: 0.9095, Val AUC: 0.8457\r\n",
      "Epoch: 047, Loss: 0.2177, Val AP: 0.9117, Val AUC: 0.8501\r\n",
      "Epoch: 048, Loss: 0.2176, Val AP: 0.9111, Val AUC: 0.8480\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8541313252917864, 'AP': 0.9161425642922802, 'F1': 0.8226466575716235, 'F0.5': 0.8718912666281087}\r\n",
      "\u001b[32m[I 2025-12-05 20:21:55,322]\u001b[0m Trial 6 finished with value: 0.9161425642922802 and parameters: {'hidden_dim': 128, 'heads': 2, 'layers': 3, 'dropout': 0.15124133386353522, 'lr': 0.00027669069113530123}. Best is trial 0 with value: 0.9195372694089661.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3158, Val AP: 0.8332, Val AUC: 0.7469\r\n",
      "Epoch: 002, Loss: 0.2971, Val AP: 0.8429, Val AUC: 0.7587\r\n",
      "Epoch: 003, Loss: 0.2899, Val AP: 0.8564, Val AUC: 0.7701\r\n",
      "Epoch: 004, Loss: 0.2824, Val AP: 0.8677, Val AUC: 0.7896\r\n",
      "Epoch: 005, Loss: 0.2790, Val AP: 0.8712, Val AUC: 0.7882\r\n",
      "Epoch: 006, Loss: 0.2743, Val AP: 0.8819, Val AUC: 0.7984\r\n",
      "Epoch: 007, Loss: 0.2711, Val AP: 0.8887, Val AUC: 0.8046\r\n",
      "Epoch: 008, Loss: 0.2677, Val AP: 0.8900, Val AUC: 0.8091\r\n",
      "Epoch: 009, Loss: 0.2665, Val AP: 0.8847, Val AUC: 0.8089\r\n",
      "Epoch: 010, Loss: 0.2647, Val AP: 0.8858, Val AUC: 0.8084\r\n",
      "Epoch: 011, Loss: 0.2647, Val AP: 0.8954, Val AUC: 0.8167\r\n",
      "Epoch: 012, Loss: 0.2615, Val AP: 0.8971, Val AUC: 0.8167\r\n",
      "Epoch: 013, Loss: 0.2631, Val AP: 0.8961, Val AUC: 0.8197\r\n",
      "Epoch: 014, Loss: 0.2594, Val AP: 0.8939, Val AUC: 0.8178\r\n",
      "Epoch: 015, Loss: 0.2620, Val AP: 0.8980, Val AUC: 0.8219\r\n",
      "Epoch: 016, Loss: 0.2594, Val AP: 0.9000, Val AUC: 0.8259\r\n",
      "Epoch: 017, Loss: 0.2565, Val AP: 0.9027, Val AUC: 0.8301\r\n",
      "Epoch: 018, Loss: 0.2534, Val AP: 0.9037, Val AUC: 0.8317\r\n",
      "Epoch: 019, Loss: 0.2506, Val AP: 0.9100, Val AUC: 0.8383\r\n",
      "Epoch: 020, Loss: 0.2489, Val AP: 0.9058, Val AUC: 0.8342\r\n",
      "Epoch: 021, Loss: 0.2475, Val AP: 0.9085, Val AUC: 0.8387\r\n",
      "Epoch: 022, Loss: 0.2448, Val AP: 0.9118, Val AUC: 0.8436\r\n",
      "Epoch: 023, Loss: 0.2437, Val AP: 0.9157, Val AUC: 0.8511\r\n",
      "Epoch: 024, Loss: 0.2418, Val AP: 0.9139, Val AUC: 0.8469\r\n",
      "Epoch: 025, Loss: 0.2407, Val AP: 0.9147, Val AUC: 0.8466\r\n",
      "Epoch: 026, Loss: 0.2386, Val AP: 0.9132, Val AUC: 0.8430\r\n",
      "Epoch: 027, Loss: 0.2395, Val AP: 0.9168, Val AUC: 0.8518\r\n",
      "Epoch: 028, Loss: 0.2386, Val AP: 0.9196, Val AUC: 0.8574\r\n",
      "Epoch: 029, Loss: 0.2384, Val AP: 0.9205, Val AUC: 0.8583\r\n",
      "Epoch: 030, Loss: 0.2374, Val AP: 0.9255, Val AUC: 0.8632\r\n",
      "Epoch: 031, Loss: 0.2356, Val AP: 0.9164, Val AUC: 0.8491\r\n",
      "Epoch: 032, Loss: 0.2367, Val AP: 0.9215, Val AUC: 0.8594\r\n",
      "Epoch: 033, Loss: 0.2341, Val AP: 0.9163, Val AUC: 0.8530\r\n",
      "Epoch: 034, Loss: 0.2344, Val AP: 0.9234, Val AUC: 0.8616\r\n",
      "Epoch: 035, Loss: 0.2346, Val AP: 0.9213, Val AUC: 0.8558\r\n",
      "Epoch: 036, Loss: 0.2319, Val AP: 0.9235, Val AUC: 0.8631\r\n",
      "Epoch: 037, Loss: 0.2329, Val AP: 0.9250, Val AUC: 0.8638\r\n",
      "Epoch: 038, Loss: 0.2319, Val AP: 0.9192, Val AUC: 0.8578\r\n",
      "Epoch: 039, Loss: 0.2324, Val AP: 0.9193, Val AUC: 0.8584\r\n",
      "Epoch: 040, Loss: 0.2309, Val AP: 0.9242, Val AUC: 0.8656\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.863244025516147, 'AP': 0.9254615656775966, 'F1': 0.8797727989902177, 'F0.5': 0.8863173957273651}\r\n",
      "\u001b[32m[I 2025-12-05 20:25:31,820]\u001b[0m Trial 7 finished with value: 0.9254615656775966 and parameters: {'hidden_dim': 64, 'heads': 8, 'layers': 2, 'dropout': 0.2568472004474476, 'lr': 0.0009398026778165655}. Best is trial 7 with value: 0.9254615656775966.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3214, Val AP: 0.8281, Val AUC: 0.7429\r\n",
      "Epoch: 002, Loss: 0.2930, Val AP: 0.8529, Val AUC: 0.7668\r\n",
      "Epoch: 003, Loss: 0.2862, Val AP: 0.8707, Val AUC: 0.7804\r\n",
      "Epoch: 004, Loss: 0.2824, Val AP: 0.8774, Val AUC: 0.7905\r\n",
      "Epoch: 005, Loss: 0.2797, Val AP: 0.8811, Val AUC: 0.7949\r\n",
      "Epoch: 006, Loss: 0.2765, Val AP: 0.8876, Val AUC: 0.8029\r\n",
      "Epoch: 007, Loss: 0.2723, Val AP: 0.8915, Val AUC: 0.8035\r\n",
      "Epoch: 008, Loss: 0.2688, Val AP: 0.8911, Val AUC: 0.8060\r\n",
      "Epoch: 009, Loss: 0.2668, Val AP: 0.8936, Val AUC: 0.8081\r\n",
      "Epoch: 010, Loss: 0.2645, Val AP: 0.8957, Val AUC: 0.8150\r\n",
      "Epoch: 011, Loss: 0.2636, Val AP: 0.8971, Val AUC: 0.8146\r\n",
      "Epoch: 012, Loss: 0.2618, Val AP: 0.8989, Val AUC: 0.8178\r\n",
      "Epoch: 013, Loss: 0.2608, Val AP: 0.8996, Val AUC: 0.8208\r\n",
      "Epoch: 014, Loss: 0.2574, Val AP: 0.9033, Val AUC: 0.8243\r\n",
      "Epoch: 015, Loss: 0.2564, Val AP: 0.9040, Val AUC: 0.8262\r\n",
      "Epoch: 016, Loss: 0.2548, Val AP: 0.9049, Val AUC: 0.8263\r\n",
      "Epoch: 017, Loss: 0.2527, Val AP: 0.9054, Val AUC: 0.8292\r\n",
      "Epoch: 018, Loss: 0.2513, Val AP: 0.9060, Val AUC: 0.8304\r\n",
      "Epoch: 019, Loss: 0.2507, Val AP: 0.9063, Val AUC: 0.8323\r\n",
      "Epoch: 020, Loss: 0.2492, Val AP: 0.9090, Val AUC: 0.8343\r\n",
      "Epoch: 021, Loss: 0.2499, Val AP: 0.9091, Val AUC: 0.8342\r\n",
      "Epoch: 022, Loss: 0.2476, Val AP: 0.9063, Val AUC: 0.8309\r\n",
      "Epoch: 023, Loss: 0.2449, Val AP: 0.9090, Val AUC: 0.8375\r\n",
      "Epoch: 024, Loss: 0.2467, Val AP: 0.9071, Val AUC: 0.8312\r\n",
      "Epoch: 025, Loss: 0.2463, Val AP: 0.9099, Val AUC: 0.8354\r\n",
      "Epoch: 026, Loss: 0.2448, Val AP: 0.9105, Val AUC: 0.8381\r\n",
      "Epoch: 027, Loss: 0.2438, Val AP: 0.9113, Val AUC: 0.8395\r\n",
      "Epoch: 028, Loss: 0.2435, Val AP: 0.9114, Val AUC: 0.8403\r\n",
      "Epoch: 029, Loss: 0.2427, Val AP: 0.9122, Val AUC: 0.8410\r\n",
      "Epoch: 030, Loss: 0.2430, Val AP: 0.9111, Val AUC: 0.8418\r\n",
      "Epoch: 031, Loss: 0.2410, Val AP: 0.9114, Val AUC: 0.8408\r\n",
      "Epoch: 032, Loss: 0.2420, Val AP: 0.9124, Val AUC: 0.8443\r\n",
      "Epoch: 033, Loss: 0.2409, Val AP: 0.9121, Val AUC: 0.8411\r\n",
      "Epoch: 034, Loss: 0.2419, Val AP: 0.9129, Val AUC: 0.8453\r\n",
      "Epoch: 035, Loss: 0.2402, Val AP: 0.9141, Val AUC: 0.8455\r\n",
      "Epoch: 036, Loss: 0.2379, Val AP: 0.9142, Val AUC: 0.8447\r\n",
      "Epoch: 037, Loss: 0.2380, Val AP: 0.9147, Val AUC: 0.8491\r\n",
      "Epoch: 038, Loss: 0.2398, Val AP: 0.9140, Val AUC: 0.8480\r\n",
      "Epoch: 039, Loss: 0.2388, Val AP: 0.9159, Val AUC: 0.8494\r\n",
      "Epoch: 040, Loss: 0.2376, Val AP: 0.9156, Val AUC: 0.8486\r\n",
      "Epoch: 041, Loss: 0.2390, Val AP: 0.9135, Val AUC: 0.8480\r\n",
      "Epoch: 042, Loss: 0.2372, Val AP: 0.9157, Val AUC: 0.8495\r\n",
      "Epoch: 043, Loss: 0.2377, Val AP: 0.9167, Val AUC: 0.8506\r\n",
      "Epoch: 044, Loss: 0.2352, Val AP: 0.9185, Val AUC: 0.8516\r\n",
      "Epoch: 045, Loss: 0.2373, Val AP: 0.9154, Val AUC: 0.8507\r\n",
      "Epoch: 046, Loss: 0.2363, Val AP: 0.9155, Val AUC: 0.8505\r\n",
      "Epoch: 047, Loss: 0.2363, Val AP: 0.9171, Val AUC: 0.8512\r\n",
      "Epoch: 048, Loss: 0.2373, Val AP: 0.9170, Val AUC: 0.8532\r\n",
      "Epoch: 049, Loss: 0.2357, Val AP: 0.9184, Val AUC: 0.8520\r\n",
      "Epoch: 050, Loss: 0.2370, Val AP: 0.9195, Val AUC: 0.8566\r\n",
      "Epoch: 051, Loss: 0.2347, Val AP: 0.9175, Val AUC: 0.8519\r\n",
      "Epoch: 052, Loss: 0.2360, Val AP: 0.9201, Val AUC: 0.8548\r\n",
      "Epoch: 053, Loss: 0.2361, Val AP: 0.9170, Val AUC: 0.8534\r\n",
      "Epoch: 054, Loss: 0.2350, Val AP: 0.9164, Val AUC: 0.8529\r\n",
      "Epoch: 055, Loss: 0.2350, Val AP: 0.9183, Val AUC: 0.8542\r\n",
      "Epoch: 056, Loss: 0.2339, Val AP: 0.9182, Val AUC: 0.8532\r\n",
      "Epoch: 057, Loss: 0.2339, Val AP: 0.9200, Val AUC: 0.8569\r\n",
      "Epoch: 058, Loss: 0.2341, Val AP: 0.9185, Val AUC: 0.8553\r\n",
      "Epoch: 059, Loss: 0.2325, Val AP: 0.9181, Val AUC: 0.8534\r\n",
      "Epoch: 060, Loss: 0.2344, Val AP: 0.9191, Val AUC: 0.8557\r\n",
      "Epoch: 061, Loss: 0.2333, Val AP: 0.9195, Val AUC: 0.8560\r\n",
      "Epoch: 062, Loss: 0.2334, Val AP: 0.9169, Val AUC: 0.8536\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8548085116362698, 'AP': 0.9200523769074913, 'F1': 0.8012465373961218, 'F0.5': 0.8583086053412462}\r\n",
      "\u001b[32m[I 2025-12-05 20:33:40,369]\u001b[0m Trial 8 finished with value: 0.9200523769074913 and parameters: {'hidden_dim': 128, 'heads': 4, 'layers': 4, 'dropout': 0.48858261545653325, 'lr': 0.00010581070899778604}. Best is trial 7 with value: 0.9254615656775966.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3063, Val AP: 0.8658, Val AUC: 0.7838\r\n",
      "Epoch: 002, Loss: 0.2914, Val AP: 0.8738, Val AUC: 0.7971\r\n",
      "Epoch: 003, Loss: 0.2834, Val AP: 0.8835, Val AUC: 0.8087\r\n",
      "Epoch: 004, Loss: 0.2816, Val AP: 0.8869, Val AUC: 0.8079\r\n",
      "Epoch: 005, Loss: 0.2775, Val AP: 0.8844, Val AUC: 0.8032\r\n",
      "Epoch: 006, Loss: 0.2769, Val AP: 0.8896, Val AUC: 0.8116\r\n",
      "Epoch: 007, Loss: 0.2767, Val AP: 0.8879, Val AUC: 0.8085\r\n",
      "Epoch: 008, Loss: 0.2758, Val AP: 0.8861, Val AUC: 0.8095\r\n",
      "Epoch: 009, Loss: 0.2748, Val AP: 0.8881, Val AUC: 0.8072\r\n",
      "Epoch: 010, Loss: 0.2702, Val AP: 0.8917, Val AUC: 0.8125\r\n",
      "Epoch: 011, Loss: 0.2722, Val AP: 0.8922, Val AUC: 0.8145\r\n",
      "Epoch: 012, Loss: 0.2706, Val AP: 0.8905, Val AUC: 0.8114\r\n",
      "Epoch: 013, Loss: 0.2687, Val AP: 0.8961, Val AUC: 0.8172\r\n",
      "Epoch: 014, Loss: 0.2678, Val AP: 0.8947, Val AUC: 0.8118\r\n",
      "Epoch: 015, Loss: 0.2648, Val AP: 0.8985, Val AUC: 0.8133\r\n",
      "Epoch: 016, Loss: 0.2658, Val AP: 0.9010, Val AUC: 0.8241\r\n",
      "Epoch: 017, Loss: 0.2664, Val AP: 0.9017, Val AUC: 0.8188\r\n",
      "Epoch: 018, Loss: 0.2628, Val AP: 0.8988, Val AUC: 0.8162\r\n",
      "Epoch: 019, Loss: 0.2641, Val AP: 0.9019, Val AUC: 0.8220\r\n",
      "Epoch: 020, Loss: 0.2654, Val AP: 0.9036, Val AUC: 0.8250\r\n",
      "Epoch: 021, Loss: 0.2632, Val AP: 0.8972, Val AUC: 0.8183\r\n",
      "Epoch: 022, Loss: 0.2613, Val AP: 0.9005, Val AUC: 0.8225\r\n",
      "Epoch: 023, Loss: 0.2607, Val AP: 0.8982, Val AUC: 0.8169\r\n",
      "Epoch: 024, Loss: 0.2590, Val AP: 0.9046, Val AUC: 0.8290\r\n",
      "Epoch: 025, Loss: 0.2593, Val AP: 0.9028, Val AUC: 0.8234\r\n",
      "Epoch: 026, Loss: 0.2594, Val AP: 0.8994, Val AUC: 0.8175\r\n",
      "Epoch: 027, Loss: 0.2595, Val AP: 0.8996, Val AUC: 0.8242\r\n",
      "Epoch: 028, Loss: 0.2583, Val AP: 0.9028, Val AUC: 0.8272\r\n",
      "Epoch: 029, Loss: 0.2572, Val AP: 0.9004, Val AUC: 0.8230\r\n",
      "Epoch: 030, Loss: 0.2543, Val AP: 0.9035, Val AUC: 0.8273\r\n",
      "Epoch: 031, Loss: 0.2567, Val AP: 0.9052, Val AUC: 0.8318\r\n",
      "Epoch: 032, Loss: 0.2561, Val AP: 0.9002, Val AUC: 0.8243\r\n",
      "Epoch: 033, Loss: 0.2571, Val AP: 0.9000, Val AUC: 0.8216\r\n",
      "Epoch: 034, Loss: 0.2561, Val AP: 0.9005, Val AUC: 0.8255\r\n",
      "Epoch: 035, Loss: 0.2559, Val AP: 0.8977, Val AUC: 0.8201\r\n",
      "Epoch: 036, Loss: 0.2533, Val AP: 0.8997, Val AUC: 0.8275\r\n",
      "Epoch: 037, Loss: 0.2560, Val AP: 0.9021, Val AUC: 0.8283\r\n",
      "Epoch: 038, Loss: 0.2525, Val AP: 0.8983, Val AUC: 0.8233\r\n",
      "Epoch: 039, Loss: 0.2540, Val AP: 0.9067, Val AUC: 0.8326\r\n",
      "Epoch: 040, Loss: 0.2527, Val AP: 0.9073, Val AUC: 0.8335\r\n",
      "Epoch: 041, Loss: 0.2543, Val AP: 0.9076, Val AUC: 0.8340\r\n",
      "Epoch: 042, Loss: 0.2531, Val AP: 0.9025, Val AUC: 0.8262\r\n",
      "Epoch: 043, Loss: 0.2517, Val AP: 0.9046, Val AUC: 0.8367\r\n",
      "Epoch: 044, Loss: 0.2509, Val AP: 0.8914, Val AUC: 0.8167\r\n",
      "Epoch: 045, Loss: 0.2505, Val AP: 0.9036, Val AUC: 0.8338\r\n",
      "Epoch: 046, Loss: 0.2494, Val AP: 0.9053, Val AUC: 0.8307\r\n",
      "Epoch: 047, Loss: 0.2507, Val AP: 0.9080, Val AUC: 0.8373\r\n",
      "Epoch: 048, Loss: 0.2460, Val AP: 0.9035, Val AUC: 0.8278\r\n",
      "Epoch: 049, Loss: 0.2478, Val AP: 0.9082, Val AUC: 0.8362\r\n",
      "Epoch: 050, Loss: 0.2472, Val AP: 0.9012, Val AUC: 0.8218\r\n",
      "Epoch: 051, Loss: 0.2502, Val AP: 0.9022, Val AUC: 0.8261\r\n",
      "Epoch: 052, Loss: 0.2499, Val AP: 0.8986, Val AUC: 0.8206\r\n",
      "Epoch: 053, Loss: 0.2487, Val AP: 0.9024, Val AUC: 0.8299\r\n",
      "Epoch: 054, Loss: 0.2496, Val AP: 0.9077, Val AUC: 0.8345\r\n",
      "Epoch: 055, Loss: 0.2483, Val AP: 0.9112, Val AUC: 0.8404\r\n",
      "Epoch: 056, Loss: 0.2464, Val AP: 0.9096, Val AUC: 0.8348\r\n",
      "Epoch: 057, Loss: 0.2507, Val AP: 0.9046, Val AUC: 0.8298\r\n",
      "Epoch: 058, Loss: 0.2461, Val AP: 0.9056, Val AUC: 0.8303\r\n",
      "Epoch: 059, Loss: 0.2466, Val AP: 0.9017, Val AUC: 0.8193\r\n",
      "Epoch: 060, Loss: 0.2482, Val AP: 0.9042, Val AUC: 0.8262\r\n",
      "Epoch: 061, Loss: 0.2480, Val AP: 0.9086, Val AUC: 0.8315\r\n",
      "Epoch: 062, Loss: 0.2454, Val AP: 0.9082, Val AUC: 0.8394\r\n",
      "Epoch: 063, Loss: 0.2476, Val AP: 0.9137, Val AUC: 0.8426\r\n",
      "Epoch: 064, Loss: 0.2448, Val AP: 0.9116, Val AUC: 0.8376\r\n",
      "Epoch: 065, Loss: 0.2498, Val AP: 0.9153, Val AUC: 0.8436\r\n",
      "Epoch: 066, Loss: 0.2442, Val AP: 0.9070, Val AUC: 0.8394\r\n",
      "Epoch: 067, Loss: 0.2472, Val AP: 0.9080, Val AUC: 0.8392\r\n",
      "Epoch: 068, Loss: 0.2462, Val AP: 0.9141, Val AUC: 0.8450\r\n",
      "Epoch: 069, Loss: 0.2476, Val AP: 0.9095, Val AUC: 0.8418\r\n",
      "Epoch: 070, Loss: 0.2469, Val AP: 0.9136, Val AUC: 0.8423\r\n",
      "Epoch: 071, Loss: 0.2452, Val AP: 0.9142, Val AUC: 0.8456\r\n",
      "Epoch: 072, Loss: 0.2452, Val AP: 0.9122, Val AUC: 0.8464\r\n",
      "Epoch: 073, Loss: 0.2455, Val AP: 0.9168, Val AUC: 0.8510\r\n",
      "Epoch: 074, Loss: 0.2457, Val AP: 0.9143, Val AUC: 0.8471\r\n",
      "Epoch: 075, Loss: 0.2460, Val AP: 0.9129, Val AUC: 0.8430\r\n",
      "Epoch: 076, Loss: 0.2457, Val AP: 0.9107, Val AUC: 0.8446\r\n",
      "Epoch: 077, Loss: 0.2456, Val AP: 0.9157, Val AUC: 0.8449\r\n",
      "Epoch: 078, Loss: 0.2433, Val AP: 0.9144, Val AUC: 0.8467\r\n",
      "Epoch: 079, Loss: 0.2464, Val AP: 0.9186, Val AUC: 0.8530\r\n",
      "Epoch: 080, Loss: 0.2441, Val AP: 0.9124, Val AUC: 0.8465\r\n",
      "Epoch: 081, Loss: 0.2420, Val AP: 0.9142, Val AUC: 0.8482\r\n",
      "Epoch: 082, Loss: 0.2442, Val AP: 0.9137, Val AUC: 0.8454\r\n",
      "Epoch: 083, Loss: 0.2437, Val AP: 0.9165, Val AUC: 0.8479\r\n",
      "Epoch: 084, Loss: 0.2443, Val AP: 0.9138, Val AUC: 0.8445\r\n",
      "Epoch: 085, Loss: 0.2439, Val AP: 0.9138, Val AUC: 0.8399\r\n",
      "Epoch: 086, Loss: 0.2450, Val AP: 0.9158, Val AUC: 0.8487\r\n",
      "Epoch: 087, Loss: 0.2417, Val AP: 0.9158, Val AUC: 0.8464\r\n",
      "Epoch: 088, Loss: 0.2429, Val AP: 0.9162, Val AUC: 0.8472\r\n",
      "Epoch: 089, Loss: 0.2431, Val AP: 0.9137, Val AUC: 0.8453\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8529914438042824, 'AP': 0.9186135227915098, 'F1': 0.8342281879194631, 'F0.5': 0.874366910523354}\r\n",
      "\u001b[32m[I 2025-12-05 20:45:04,664]\u001b[0m Trial 9 finished with value: 0.9186135227915098 and parameters: {'hidden_dim': 32, 'heads': 4, 'layers': 4, 'dropout': 0.48983524680861357, 'lr': 0.0017683331569931895}. Best is trial 7 with value: 0.9254615656775966.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3187, Val AP: 0.8278, Val AUC: 0.7439\r\n",
      "Epoch: 002, Loss: 0.3049, Val AP: 0.8484, Val AUC: 0.7609\r\n",
      "Epoch: 003, Loss: 0.2954, Val AP: 0.8520, Val AUC: 0.7767\r\n",
      "Epoch: 004, Loss: 0.2901, Val AP: 0.8295, Val AUC: 0.7477\r\n",
      "Epoch: 005, Loss: 0.2868, Val AP: 0.8512, Val AUC: 0.7756\r\n",
      "Epoch: 006, Loss: 0.2863, Val AP: 0.8503, Val AUC: 0.7732\r\n",
      "Epoch: 007, Loss: 0.2864, Val AP: 0.8473, Val AUC: 0.7737\r\n",
      "Epoch: 008, Loss: 0.2785, Val AP: 0.8431, Val AUC: 0.7563\r\n",
      "Epoch: 009, Loss: 0.2772, Val AP: 0.8687, Val AUC: 0.7955\r\n",
      "Epoch: 010, Loss: 0.2808, Val AP: 0.8589, Val AUC: 0.7876\r\n",
      "Epoch: 011, Loss: 0.2797, Val AP: 0.8556, Val AUC: 0.7868\r\n",
      "Epoch: 012, Loss: 0.2762, Val AP: 0.8607, Val AUC: 0.7937\r\n",
      "Epoch: 013, Loss: 0.2794, Val AP: 0.8638, Val AUC: 0.7906\r\n",
      "Epoch: 014, Loss: 0.3027, Val AP: 0.8523, Val AUC: 0.7791\r\n",
      "Epoch: 015, Loss: 0.2766, Val AP: 0.8636, Val AUC: 0.8016\r\n",
      "Epoch: 016, Loss: 0.2741, Val AP: 0.8579, Val AUC: 0.7934\r\n",
      "Epoch: 017, Loss: 0.2908, Val AP: 0.8623, Val AUC: 0.7909\r\n",
      "Epoch: 018, Loss: 0.2704, Val AP: 0.8593, Val AUC: 0.7895\r\n",
      "Epoch: 019, Loss: 0.2722, Val AP: 0.8694, Val AUC: 0.8008\r\n",
      "Epoch: 020, Loss: 0.2759, Val AP: 0.8617, Val AUC: 0.7965\r\n",
      "Epoch: 021, Loss: 0.2873, Val AP: 0.8606, Val AUC: 0.7886\r\n",
      "Epoch: 022, Loss: 0.2746, Val AP: 0.8678, Val AUC: 0.7973\r\n",
      "Epoch: 023, Loss: 0.2695, Val AP: 0.8756, Val AUC: 0.8018\r\n",
      "Epoch: 024, Loss: 0.2747, Val AP: 0.8664, Val AUC: 0.7971\r\n",
      "Epoch: 025, Loss: 0.2745, Val AP: 0.8749, Val AUC: 0.8008\r\n",
      "Epoch: 026, Loss: 0.2800, Val AP: 0.8682, Val AUC: 0.7926\r\n",
      "Epoch: 027, Loss: 0.2713, Val AP: 0.8730, Val AUC: 0.8031\r\n",
      "Epoch: 028, Loss: 0.2753, Val AP: 0.8642, Val AUC: 0.7945\r\n",
      "Epoch: 029, Loss: 0.2695, Val AP: 0.8682, Val AUC: 0.8011\r\n",
      "Epoch: 030, Loss: 0.2737, Val AP: 0.8726, Val AUC: 0.8006\r\n",
      "Epoch: 031, Loss: 0.2732, Val AP: 0.8720, Val AUC: 0.7928\r\n",
      "Epoch: 032, Loss: 0.2731, Val AP: 0.8692, Val AUC: 0.8011\r\n",
      "Epoch: 033, Loss: 0.2724, Val AP: 0.8679, Val AUC: 0.7987\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.801769576841595, 'AP': 0.8755752013054352, 'F1': 0.6975497702909648, 'F0.5': 0.8081973030518098}\r\n",
      "\u001b[32m[I 2025-12-05 20:48:05,467]\u001b[0m Trial 10 finished with value: 0.8755752013054352 and parameters: {'hidden_dim': 64, 'heads': 8, 'layers': 2, 'dropout': 0.38303500751958386, 'lr': 0.006933673674371564}. Best is trial 7 with value: 0.9254615656775966.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3145, Val AP: 0.8343, Val AUC: 0.7524\r\n",
      "Epoch: 002, Loss: 0.2915, Val AP: 0.8490, Val AUC: 0.7642\r\n",
      "Epoch: 003, Loss: 0.2860, Val AP: 0.8702, Val AUC: 0.7805\r\n",
      "Epoch: 004, Loss: 0.2820, Val AP: 0.8755, Val AUC: 0.7862\r\n",
      "Epoch: 005, Loss: 0.2763, Val AP: 0.8804, Val AUC: 0.7911\r\n",
      "Epoch: 006, Loss: 0.2739, Val AP: 0.8827, Val AUC: 0.7970\r\n",
      "Epoch: 007, Loss: 0.2706, Val AP: 0.8826, Val AUC: 0.7905\r\n",
      "Epoch: 008, Loss: 0.2693, Val AP: 0.8890, Val AUC: 0.7989\r\n",
      "Epoch: 009, Loss: 0.2670, Val AP: 0.8887, Val AUC: 0.7995\r\n",
      "Epoch: 010, Loss: 0.2652, Val AP: 0.8904, Val AUC: 0.8032\r\n",
      "Epoch: 011, Loss: 0.2661, Val AP: 0.8923, Val AUC: 0.8064\r\n",
      "Epoch: 012, Loss: 0.2644, Val AP: 0.8935, Val AUC: 0.8098\r\n",
      "Epoch: 013, Loss: 0.2639, Val AP: 0.8926, Val AUC: 0.8081\r\n",
      "Epoch: 014, Loss: 0.2631, Val AP: 0.8989, Val AUC: 0.8148\r\n",
      "Epoch: 015, Loss: 0.2636, Val AP: 0.8961, Val AUC: 0.8096\r\n",
      "Epoch: 016, Loss: 0.2628, Val AP: 0.8942, Val AUC: 0.8108\r\n",
      "Epoch: 017, Loss: 0.2629, Val AP: 0.8952, Val AUC: 0.8124\r\n",
      "Epoch: 018, Loss: 0.2618, Val AP: 0.8965, Val AUC: 0.8137\r\n",
      "Epoch: 019, Loss: 0.2607, Val AP: 0.8949, Val AUC: 0.8104\r\n",
      "Epoch: 020, Loss: 0.2613, Val AP: 0.8968, Val AUC: 0.8134\r\n",
      "Epoch: 021, Loss: 0.2601, Val AP: 0.8937, Val AUC: 0.8079\r\n",
      "Epoch: 022, Loss: 0.2610, Val AP: 0.8966, Val AUC: 0.8146\r\n",
      "Epoch: 023, Loss: 0.2595, Val AP: 0.8997, Val AUC: 0.8181\r\n",
      "Epoch: 024, Loss: 0.2589, Val AP: 0.9004, Val AUC: 0.8157\r\n",
      "Epoch: 025, Loss: 0.2584, Val AP: 0.8973, Val AUC: 0.8108\r\n",
      "Epoch: 026, Loss: 0.2579, Val AP: 0.8995, Val AUC: 0.8146\r\n",
      "Epoch: 027, Loss: 0.2571, Val AP: 0.8987, Val AUC: 0.8193\r\n",
      "Epoch: 028, Loss: 0.2562, Val AP: 0.9029, Val AUC: 0.8215\r\n",
      "Epoch: 029, Loss: 0.2543, Val AP: 0.9015, Val AUC: 0.8217\r\n",
      "Epoch: 030, Loss: 0.2552, Val AP: 0.9029, Val AUC: 0.8214\r\n",
      "Epoch: 031, Loss: 0.2536, Val AP: 0.9031, Val AUC: 0.8217\r\n",
      "Epoch: 032, Loss: 0.2525, Val AP: 0.9012, Val AUC: 0.8188\r\n",
      "Epoch: 033, Loss: 0.2532, Val AP: 0.9027, Val AUC: 0.8206\r\n",
      "Epoch: 034, Loss: 0.2510, Val AP: 0.9037, Val AUC: 0.8212\r\n",
      "Epoch: 035, Loss: 0.2504, Val AP: 0.9045, Val AUC: 0.8242\r\n",
      "Epoch: 036, Loss: 0.2503, Val AP: 0.9051, Val AUC: 0.8251\r\n",
      "Epoch: 037, Loss: 0.2484, Val AP: 0.8974, Val AUC: 0.8093\r\n",
      "Epoch: 038, Loss: 0.2478, Val AP: 0.9075, Val AUC: 0.8312\r\n",
      "Epoch: 039, Loss: 0.2475, Val AP: 0.9089, Val AUC: 0.8302\r\n",
      "Epoch: 040, Loss: 0.2451, Val AP: 0.9073, Val AUC: 0.8290\r\n",
      "Epoch: 041, Loss: 0.2460, Val AP: 0.9106, Val AUC: 0.8344\r\n",
      "Epoch: 042, Loss: 0.2433, Val AP: 0.9092, Val AUC: 0.8319\r\n",
      "Epoch: 043, Loss: 0.2434, Val AP: 0.9132, Val AUC: 0.8383\r\n",
      "Epoch: 044, Loss: 0.2429, Val AP: 0.9104, Val AUC: 0.8337\r\n",
      "Epoch: 045, Loss: 0.2425, Val AP: 0.9114, Val AUC: 0.8374\r\n",
      "Epoch: 046, Loss: 0.2411, Val AP: 0.9081, Val AUC: 0.8336\r\n",
      "Epoch: 047, Loss: 0.2413, Val AP: 0.9111, Val AUC: 0.8381\r\n",
      "Epoch: 048, Loss: 0.2423, Val AP: 0.9116, Val AUC: 0.8383\r\n",
      "Epoch: 049, Loss: 0.2420, Val AP: 0.9133, Val AUC: 0.8436\r\n",
      "Epoch: 050, Loss: 0.2401, Val AP: 0.9096, Val AUC: 0.8336\r\n",
      "Epoch: 051, Loss: 0.2394, Val AP: 0.9117, Val AUC: 0.8371\r\n",
      "Epoch: 052, Loss: 0.2409, Val AP: 0.9104, Val AUC: 0.8338\r\n",
      "Epoch: 053, Loss: 0.2406, Val AP: 0.9126, Val AUC: 0.8395\r\n",
      "Epoch: 054, Loss: 0.2401, Val AP: 0.9113, Val AUC: 0.8385\r\n",
      "Epoch: 055, Loss: 0.2395, Val AP: 0.9124, Val AUC: 0.8390\r\n",
      "Epoch: 056, Loss: 0.2406, Val AP: 0.9125, Val AUC: 0.8401\r\n",
      "Epoch: 057, Loss: 0.2391, Val AP: 0.9126, Val AUC: 0.8432\r\n",
      "Epoch: 058, Loss: 0.2403, Val AP: 0.9135, Val AUC: 0.8420\r\n",
      "Epoch: 059, Loss: 0.2385, Val AP: 0.9130, Val AUC: 0.8422\r\n",
      "Epoch: 060, Loss: 0.2385, Val AP: 0.9148, Val AUC: 0.8463\r\n",
      "Epoch: 061, Loss: 0.2383, Val AP: 0.9116, Val AUC: 0.8402\r\n",
      "Epoch: 062, Loss: 0.2393, Val AP: 0.9137, Val AUC: 0.8440\r\n",
      "Epoch: 063, Loss: 0.2385, Val AP: 0.9138, Val AUC: 0.8401\r\n",
      "Epoch: 064, Loss: 0.2399, Val AP: 0.9129, Val AUC: 0.8415\r\n",
      "Epoch: 065, Loss: 0.2370, Val AP: 0.9140, Val AUC: 0.8423\r\n",
      "Epoch: 066, Loss: 0.2391, Val AP: 0.9127, Val AUC: 0.8409\r\n",
      "Epoch: 067, Loss: 0.2375, Val AP: 0.9104, Val AUC: 0.8341\r\n",
      "Epoch: 068, Loss: 0.2387, Val AP: 0.9143, Val AUC: 0.8435\r\n",
      "Epoch: 069, Loss: 0.2360, Val AP: 0.9142, Val AUC: 0.8422\r\n",
      "Epoch: 070, Loss: 0.2378, Val AP: 0.9162, Val AUC: 0.8454\r\n",
      "Epoch: 071, Loss: 0.2363, Val AP: 0.9137, Val AUC: 0.8430\r\n",
      "Epoch: 072, Loss: 0.2374, Val AP: 0.9140, Val AUC: 0.8442\r\n",
      "Epoch: 073, Loss: 0.2370, Val AP: 0.9142, Val AUC: 0.8442\r\n",
      "Epoch: 074, Loss: 0.2369, Val AP: 0.9151, Val AUC: 0.8455\r\n",
      "Epoch: 075, Loss: 0.2366, Val AP: 0.9156, Val AUC: 0.8474\r\n",
      "Epoch: 076, Loss: 0.2371, Val AP: 0.9141, Val AUC: 0.8457\r\n",
      "Epoch: 077, Loss: 0.2364, Val AP: 0.9143, Val AUC: 0.8434\r\n",
      "Epoch: 078, Loss: 0.2372, Val AP: 0.9154, Val AUC: 0.8473\r\n",
      "Epoch: 079, Loss: 0.2349, Val AP: 0.9146, Val AUC: 0.8457\r\n",
      "Epoch: 080, Loss: 0.2340, Val AP: 0.9154, Val AUC: 0.8479\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8454524933747136, 'AP': 0.9161964448306856, 'F1': 0.8105335157318742, 'F0.5': 0.860691458454387}\r\n",
      "\u001b[32m[I 2025-12-05 21:02:11,615]\u001b[0m Trial 11 finished with value: 0.9161964448306856 and parameters: {'hidden_dim': 128, 'heads': 8, 'layers': 4, 'dropout': 0.4937929175868376, 'lr': 0.00011114131195208284}. Best is trial 7 with value: 0.9254615656775966.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3110, Val AP: 0.8547, Val AUC: 0.7562\r\n",
      "Epoch: 002, Loss: 0.2912, Val AP: 0.8481, Val AUC: 0.7628\r\n",
      "Epoch: 003, Loss: 0.2858, Val AP: 0.8675, Val AUC: 0.7769\r\n",
      "Epoch: 004, Loss: 0.2818, Val AP: 0.8765, Val AUC: 0.7881\r\n",
      "Epoch: 005, Loss: 0.2755, Val AP: 0.8762, Val AUC: 0.7911\r\n",
      "Epoch: 006, Loss: 0.2728, Val AP: 0.8884, Val AUC: 0.8013\r\n",
      "Epoch: 007, Loss: 0.2692, Val AP: 0.8918, Val AUC: 0.8064\r\n",
      "Epoch: 008, Loss: 0.2670, Val AP: 0.8905, Val AUC: 0.8030\r\n",
      "Epoch: 009, Loss: 0.2664, Val AP: 0.8911, Val AUC: 0.8045\r\n",
      "Epoch: 010, Loss: 0.2649, Val AP: 0.8992, Val AUC: 0.8146\r\n",
      "Epoch: 011, Loss: 0.2628, Val AP: 0.8948, Val AUC: 0.8094\r\n",
      "Epoch: 012, Loss: 0.2623, Val AP: 0.8970, Val AUC: 0.8110\r\n",
      "Epoch: 013, Loss: 0.2630, Val AP: 0.8993, Val AUC: 0.8162\r\n",
      "Epoch: 014, Loss: 0.2583, Val AP: 0.9019, Val AUC: 0.8207\r\n",
      "Epoch: 015, Loss: 0.2594, Val AP: 0.9020, Val AUC: 0.8213\r\n",
      "Epoch: 016, Loss: 0.2591, Val AP: 0.9029, Val AUC: 0.8187\r\n",
      "Epoch: 017, Loss: 0.2590, Val AP: 0.9023, Val AUC: 0.8226\r\n",
      "Epoch: 018, Loss: 0.2567, Val AP: 0.9008, Val AUC: 0.8157\r\n",
      "Epoch: 019, Loss: 0.2552, Val AP: 0.9037, Val AUC: 0.8247\r\n",
      "Epoch: 020, Loss: 0.2561, Val AP: 0.9038, Val AUC: 0.8259\r\n",
      "Epoch: 021, Loss: 0.2535, Val AP: 0.9036, Val AUC: 0.8227\r\n",
      "Epoch: 022, Loss: 0.2541, Val AP: 0.9045, Val AUC: 0.8264\r\n",
      "Epoch: 023, Loss: 0.2540, Val AP: 0.9065, Val AUC: 0.8269\r\n",
      "Epoch: 024, Loss: 0.2540, Val AP: 0.9074, Val AUC: 0.8312\r\n",
      "Epoch: 025, Loss: 0.2526, Val AP: 0.9060, Val AUC: 0.8261\r\n",
      "Epoch: 026, Loss: 0.2509, Val AP: 0.9033, Val AUC: 0.8196\r\n",
      "Epoch: 027, Loss: 0.2500, Val AP: 0.9088, Val AUC: 0.8300\r\n",
      "Epoch: 028, Loss: 0.2496, Val AP: 0.9067, Val AUC: 0.8273\r\n",
      "Epoch: 029, Loss: 0.2494, Val AP: 0.9073, Val AUC: 0.8301\r\n",
      "Epoch: 030, Loss: 0.2472, Val AP: 0.9096, Val AUC: 0.8346\r\n",
      "Epoch: 031, Loss: 0.2470, Val AP: 0.9078, Val AUC: 0.8297\r\n",
      "Epoch: 032, Loss: 0.2473, Val AP: 0.9078, Val AUC: 0.8285\r\n",
      "Epoch: 033, Loss: 0.2468, Val AP: 0.9094, Val AUC: 0.8331\r\n",
      "Epoch: 034, Loss: 0.2451, Val AP: 0.9106, Val AUC: 0.8347\r\n",
      "Epoch: 035, Loss: 0.2441, Val AP: 0.9095, Val AUC: 0.8305\r\n",
      "Epoch: 036, Loss: 0.2454, Val AP: 0.9120, Val AUC: 0.8362\r\n",
      "Epoch: 037, Loss: 0.2427, Val AP: 0.9093, Val AUC: 0.8320\r\n",
      "Epoch: 038, Loss: 0.2433, Val AP: 0.9110, Val AUC: 0.8346\r\n",
      "Epoch: 039, Loss: 0.2437, Val AP: 0.9129, Val AUC: 0.8374\r\n",
      "Epoch: 040, Loss: 0.2427, Val AP: 0.9104, Val AUC: 0.8319\r\n",
      "Epoch: 041, Loss: 0.2440, Val AP: 0.9066, Val AUC: 0.8268\r\n",
      "Epoch: 042, Loss: 0.2418, Val AP: 0.9133, Val AUC: 0.8387\r\n",
      "Epoch: 043, Loss: 0.2414, Val AP: 0.9149, Val AUC: 0.8403\r\n",
      "Epoch: 044, Loss: 0.2426, Val AP: 0.9085, Val AUC: 0.8304\r\n",
      "Epoch: 045, Loss: 0.2405, Val AP: 0.9132, Val AUC: 0.8384\r\n",
      "Epoch: 046, Loss: 0.2414, Val AP: 0.9138, Val AUC: 0.8403\r\n",
      "Epoch: 047, Loss: 0.2393, Val AP: 0.9178, Val AUC: 0.8446\r\n",
      "Epoch: 048, Loss: 0.2397, Val AP: 0.9136, Val AUC: 0.8366\r\n",
      "Epoch: 049, Loss: 0.2396, Val AP: 0.9146, Val AUC: 0.8415\r\n",
      "Epoch: 050, Loss: 0.2379, Val AP: 0.9182, Val AUC: 0.8462\r\n",
      "Epoch: 051, Loss: 0.2378, Val AP: 0.9138, Val AUC: 0.8367\r\n",
      "Epoch: 052, Loss: 0.2378, Val AP: 0.9184, Val AUC: 0.8456\r\n",
      "Epoch: 053, Loss: 0.2368, Val AP: 0.9180, Val AUC: 0.8450\r\n",
      "Epoch: 054, Loss: 0.2367, Val AP: 0.9199, Val AUC: 0.8508\r\n",
      "Epoch: 055, Loss: 0.2366, Val AP: 0.9209, Val AUC: 0.8504\r\n",
      "Epoch: 056, Loss: 0.2345, Val AP: 0.9221, Val AUC: 0.8530\r\n",
      "Epoch: 057, Loss: 0.2367, Val AP: 0.9233, Val AUC: 0.8549\r\n",
      "Epoch: 058, Loss: 0.2346, Val AP: 0.9228, Val AUC: 0.8533\r\n",
      "Epoch: 059, Loss: 0.2346, Val AP: 0.9229, Val AUC: 0.8530\r\n",
      "Epoch: 060, Loss: 0.2322, Val AP: 0.9247, Val AUC: 0.8578\r\n",
      "Epoch: 061, Loss: 0.2310, Val AP: 0.9242, Val AUC: 0.8563\r\n",
      "Epoch: 062, Loss: 0.2303, Val AP: 0.9253, Val AUC: 0.8576\r\n",
      "Epoch: 063, Loss: 0.2304, Val AP: 0.9274, Val AUC: 0.8628\r\n",
      "Epoch: 064, Loss: 0.2301, Val AP: 0.9325, Val AUC: 0.8702\r\n",
      "Epoch: 065, Loss: 0.2263, Val AP: 0.9297, Val AUC: 0.8667\r\n",
      "Epoch: 066, Loss: 0.2268, Val AP: 0.9315, Val AUC: 0.8673\r\n",
      "Epoch: 067, Loss: 0.2268, Val AP: 0.9282, Val AUC: 0.8632\r\n",
      "Epoch: 068, Loss: 0.2253, Val AP: 0.9318, Val AUC: 0.8702\r\n",
      "Epoch: 069, Loss: 0.2268, Val AP: 0.9294, Val AUC: 0.8663\r\n",
      "Epoch: 070, Loss: 0.2240, Val AP: 0.9306, Val AUC: 0.8688\r\n",
      "Epoch: 071, Loss: 0.2254, Val AP: 0.9334, Val AUC: 0.8721\r\n",
      "Epoch: 072, Loss: 0.2234, Val AP: 0.9326, Val AUC: 0.8713\r\n",
      "Epoch: 073, Loss: 0.2253, Val AP: 0.9316, Val AUC: 0.8714\r\n",
      "Epoch: 074, Loss: 0.2234, Val AP: 0.9347, Val AUC: 0.8744\r\n",
      "Epoch: 075, Loss: 0.2237, Val AP: 0.9339, Val AUC: 0.8735\r\n",
      "Epoch: 076, Loss: 0.2204, Val AP: 0.9334, Val AUC: 0.8743\r\n",
      "Epoch: 077, Loss: 0.2225, Val AP: 0.9344, Val AUC: 0.8750\r\n",
      "Epoch: 078, Loss: 0.2224, Val AP: 0.9345, Val AUC: 0.8759\r\n",
      "Epoch: 079, Loss: 0.2206, Val AP: 0.9353, Val AUC: 0.8759\r\n",
      "Epoch: 080, Loss: 0.2213, Val AP: 0.9329, Val AUC: 0.8738\r\n",
      "Epoch: 081, Loss: 0.2211, Val AP: 0.9366, Val AUC: 0.8789\r\n",
      "Epoch: 082, Loss: 0.2211, Val AP: 0.9347, Val AUC: 0.8768\r\n",
      "Epoch: 083, Loss: 0.2199, Val AP: 0.9349, Val AUC: 0.8774\r\n",
      "Epoch: 084, Loss: 0.2202, Val AP: 0.9360, Val AUC: 0.8771\r\n",
      "Epoch: 085, Loss: 0.2207, Val AP: 0.9333, Val AUC: 0.8751\r\n",
      "Epoch: 086, Loss: 0.2207, Val AP: 0.9360, Val AUC: 0.8781\r\n",
      "Epoch: 087, Loss: 0.2196, Val AP: 0.9356, Val AUC: 0.8779\r\n",
      "Epoch: 088, Loss: 0.2230, Val AP: 0.9342, Val AUC: 0.8777\r\n",
      "Epoch: 089, Loss: 0.2208, Val AP: 0.9349, Val AUC: 0.8768\r\n",
      "Epoch: 090, Loss: 0.2198, Val AP: 0.9337, Val AUC: 0.8760\r\n",
      "Epoch: 091, Loss: 0.2182, Val AP: 0.9368, Val AUC: 0.8804\r\n",
      "Epoch: 092, Loss: 0.2195, Val AP: 0.9364, Val AUC: 0.8794\r\n",
      "Epoch: 093, Loss: 0.2190, Val AP: 0.9367, Val AUC: 0.8808\r\n",
      "Epoch: 094, Loss: 0.2179, Val AP: 0.9368, Val AUC: 0.8806\r\n",
      "Epoch: 095, Loss: 0.2190, Val AP: 0.9372, Val AUC: 0.8814\r\n",
      "Epoch: 096, Loss: 0.2191, Val AP: 0.9369, Val AUC: 0.8799\r\n",
      "Epoch: 097, Loss: 0.2184, Val AP: 0.9377, Val AUC: 0.8818\r\n",
      "Epoch: 098, Loss: 0.2170, Val AP: 0.9377, Val AUC: 0.8815\r\n",
      "Epoch: 099, Loss: 0.2184, Val AP: 0.9345, Val AUC: 0.8757\r\n",
      "Epoch: 100, Loss: 0.2190, Val AP: 0.9369, Val AUC: 0.8798\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.881460631337018, 'AP': 0.9377283745919043, 'F1': 0.8543946932006632, 'F0.5': 0.8885209713024284}\r\n",
      "\u001b[32m[I 2025-12-05 21:19:49,130]\u001b[0m Trial 12 finished with value: 0.9377283745919043 and parameters: {'hidden_dim': 128, 'heads': 8, 'layers': 4, 'dropout': 0.4280377882783445, 'lr': 0.0001243498224639157}. Best is trial 12 with value: 0.9377283745919043.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3118, Val AP: 0.8442, Val AUC: 0.7615\r\n",
      "Epoch: 002, Loss: 0.2965, Val AP: 0.8595, Val AUC: 0.7787\r\n",
      "Epoch: 003, Loss: 0.2920, Val AP: 0.8608, Val AUC: 0.7817\r\n",
      "Epoch: 004, Loss: 0.2842, Val AP: 0.8649, Val AUC: 0.7885\r\n",
      "Epoch: 005, Loss: 0.2869, Val AP: 0.8691, Val AUC: 0.7971\r\n",
      "Epoch: 006, Loss: 0.2825, Val AP: 0.8677, Val AUC: 0.7877\r\n",
      "Epoch: 007, Loss: 0.2972, Val AP: 0.8737, Val AUC: 0.7985\r\n",
      "Epoch: 008, Loss: 0.2847, Val AP: 0.8739, Val AUC: 0.7937\r\n",
      "Epoch: 009, Loss: 0.2854, Val AP: 0.8744, Val AUC: 0.7961\r\n",
      "Epoch: 010, Loss: 0.2781, Val AP: 0.8741, Val AUC: 0.7948\r\n",
      "Epoch: 011, Loss: 0.2779, Val AP: 0.8707, Val AUC: 0.7951\r\n",
      "Epoch: 012, Loss: 0.2992, Val AP: 0.8710, Val AUC: 0.7974\r\n",
      "Epoch: 013, Loss: 0.2807, Val AP: 0.8769, Val AUC: 0.7999\r\n",
      "Epoch: 014, Loss: 0.2766, Val AP: 0.8784, Val AUC: 0.8038\r\n",
      "Epoch: 015, Loss: 0.3559, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 016, Loss: 0.3534, Val AP: 0.8391, Val AUC: 0.7318\r\n",
      "Epoch: 017, Loss: 0.3244, Val AP: 0.8722, Val AUC: 0.7952\r\n",
      "Epoch: 018, Loss: 0.2842, Val AP: 0.8666, Val AUC: 0.7840\r\n",
      "Epoch: 019, Loss: 0.2799, Val AP: 0.8711, Val AUC: 0.7934\r\n",
      "Epoch: 020, Loss: 0.2795, Val AP: 0.8718, Val AUC: 0.7946\r\n",
      "Epoch: 021, Loss: 0.2991, Val AP: 0.7154, Val AUC: 0.5000\r\n",
      "Epoch: 022, Loss: 0.3529, Val AP: 0.8460, Val AUC: 0.7691\r\n",
      "Epoch: 023, Loss: 0.2861, Val AP: 0.8726, Val AUC: 0.7967\r\n",
      "Epoch: 024, Loss: 0.2761, Val AP: 0.8724, Val AUC: 0.7943\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8037942956089401, 'AP': 0.8784180472609537, 'F1': 0.7744827586206897, 'F0.5': 0.8271950500883913}\r\n",
      "\u001b[32m[I 2025-12-05 21:23:07,875]\u001b[0m Trial 13 finished with value: 0.8784180472609537 and parameters: {'hidden_dim': 64, 'heads': 8, 'layers': 4, 'dropout': 0.4074241281691797, 'lr': 0.0028419509685124384}. Best is trial 12 with value: 0.9377283745919043.\u001b[0m\r\n",
      "Using device: cuda\r\n",
      "Epoch: 001, Loss: 0.3137, Val AP: 0.8327, Val AUC: 0.7498\r\n",
      "Epoch: 002, Loss: 0.2912, Val AP: 0.8556, Val AUC: 0.7695\r\n",
      "Epoch: 003, Loss: 0.2864, Val AP: 0.8647, Val AUC: 0.7770\r\n",
      "Epoch: 004, Loss: 0.2822, Val AP: 0.8730, Val AUC: 0.7828\r\n",
      "Epoch: 005, Loss: 0.2764, Val AP: 0.8835, Val AUC: 0.7989\r\n",
      "Epoch: 006, Loss: 0.2723, Val AP: 0.8839, Val AUC: 0.7936\r\n",
      "Epoch: 007, Loss: 0.2701, Val AP: 0.8873, Val AUC: 0.8059\r\n",
      "Epoch: 008, Loss: 0.2657, Val AP: 0.8936, Val AUC: 0.8068\r\n",
      "Epoch: 009, Loss: 0.2606, Val AP: 0.8947, Val AUC: 0.8120\r\n",
      "Epoch: 010, Loss: 0.2596, Val AP: 0.8956, Val AUC: 0.8171\r\n",
      "Epoch: 011, Loss: 0.2556, Val AP: 0.8987, Val AUC: 0.8194\r\n",
      "Epoch: 012, Loss: 0.2524, Val AP: 0.8999, Val AUC: 0.8196\r\n",
      "Epoch: 013, Loss: 0.2510, Val AP: 0.8986, Val AUC: 0.8234\r\n",
      "Epoch: 014, Loss: 0.2493, Val AP: 0.9012, Val AUC: 0.8244\r\n",
      "Epoch: 015, Loss: 0.2478, Val AP: 0.8959, Val AUC: 0.8175\r\n",
      "Epoch: 016, Loss: 0.2445, Val AP: 0.9063, Val AUC: 0.8299\r\n",
      "Epoch: 017, Loss: 0.2452, Val AP: 0.9083, Val AUC: 0.8326\r\n",
      "Epoch: 018, Loss: 0.2449, Val AP: 0.9077, Val AUC: 0.8329\r\n",
      "Epoch: 019, Loss: 0.2419, Val AP: 0.9068, Val AUC: 0.8291\r\n",
      "Epoch: 020, Loss: 0.2413, Val AP: 0.9097, Val AUC: 0.8367\r\n",
      "Epoch: 021, Loss: 0.2398, Val AP: 0.9090, Val AUC: 0.8346\r\n",
      "Epoch: 022, Loss: 0.2384, Val AP: 0.9075, Val AUC: 0.8345\r\n",
      "Epoch: 023, Loss: 0.2388, Val AP: 0.9123, Val AUC: 0.8427\r\n",
      "Epoch: 024, Loss: 0.2368, Val AP: 0.9114, Val AUC: 0.8381\r\n",
      "Epoch: 025, Loss: 0.2357, Val AP: 0.9120, Val AUC: 0.8395\r\n",
      "Epoch: 026, Loss: 0.2347, Val AP: 0.9120, Val AUC: 0.8446\r\n",
      "Epoch: 027, Loss: 0.2316, Val AP: 0.9166, Val AUC: 0.8469\r\n",
      "Epoch: 028, Loss: 0.2328, Val AP: 0.9166, Val AUC: 0.8485\r\n",
      "Epoch: 029, Loss: 0.2301, Val AP: 0.9204, Val AUC: 0.8572\r\n",
      "Epoch: 030, Loss: 0.2267, Val AP: 0.9183, Val AUC: 0.8572\r\n",
      "Epoch: 031, Loss: 0.2270, Val AP: 0.9227, Val AUC: 0.8613\r\n",
      "Epoch: 032, Loss: 0.2260, Val AP: 0.9233, Val AUC: 0.8630\r\n",
      "Epoch: 033, Loss: 0.2236, Val AP: 0.9285, Val AUC: 0.8683\r\n",
      "Epoch: 034, Loss: 0.2220, Val AP: 0.9285, Val AUC: 0.8694\r\n",
      "Epoch: 035, Loss: 0.2219, Val AP: 0.9251, Val AUC: 0.8707\r\n",
      "Epoch: 036, Loss: 0.2223, Val AP: 0.9299, Val AUC: 0.8699\r\n",
      "Epoch: 037, Loss: 0.2200, Val AP: 0.9259, Val AUC: 0.8696\r\n",
      "Epoch: 038, Loss: 0.2206, Val AP: 0.9275, Val AUC: 0.8710\r\n",
      "Epoch: 039, Loss: 0.2208, Val AP: 0.9292, Val AUC: 0.8712\r\n",
      "Epoch: 040, Loss: 0.2184, Val AP: 0.9291, Val AUC: 0.8756\r\n",
      "Epoch: 041, Loss: 0.2198, Val AP: 0.9295, Val AUC: 0.8774\r\n",
      "Epoch: 042, Loss: 0.2158, Val AP: 0.9328, Val AUC: 0.8774\r\n",
      "Epoch: 043, Loss: 0.2173, Val AP: 0.9260, Val AUC: 0.8714\r\n",
      "Epoch: 044, Loss: 0.2169, Val AP: 0.9281, Val AUC: 0.8746\r\n",
      "Epoch: 045, Loss: 0.2162, Val AP: 0.9365, Val AUC: 0.8839\r\n",
      "Epoch: 046, Loss: 0.2160, Val AP: 0.9279, Val AUC: 0.8804\r\n",
      "Epoch: 047, Loss: 0.2147, Val AP: 0.9371, Val AUC: 0.8843\r\n",
      "Epoch: 048, Loss: 0.2138, Val AP: 0.9313, Val AUC: 0.8806\r\n",
      "Epoch: 049, Loss: 0.2122, Val AP: 0.9372, Val AUC: 0.8862\r\n",
      "Epoch: 050, Loss: 0.2123, Val AP: 0.9378, Val AUC: 0.8859\r\n",
      "Epoch: 051, Loss: 0.2130, Val AP: 0.9393, Val AUC: 0.8856\r\n",
      "Epoch: 052, Loss: 0.2130, Val AP: 0.9381, Val AUC: 0.8857\r\n",
      "Epoch: 053, Loss: 0.2122, Val AP: 0.9378, Val AUC: 0.8864\r\n",
      "Epoch: 054, Loss: 0.2121, Val AP: 0.9371, Val AUC: 0.8845\r\n",
      "Epoch: 055, Loss: 0.2109, Val AP: 0.9381, Val AUC: 0.8858\r\n",
      "Epoch: 056, Loss: 0.2102, Val AP: 0.9410, Val AUC: 0.8893\r\n",
      "Epoch: 057, Loss: 0.2126, Val AP: 0.9363, Val AUC: 0.8853\r\n",
      "Epoch: 058, Loss: 0.2091, Val AP: 0.9396, Val AUC: 0.8885\r\n",
      "Epoch: 059, Loss: 0.2104, Val AP: 0.9418, Val AUC: 0.8905\r\n",
      "Epoch: 060, Loss: 0.2096, Val AP: 0.9416, Val AUC: 0.8900\r\n",
      "Epoch: 061, Loss: 0.2095, Val AP: 0.9401, Val AUC: 0.8898\r\n",
      "Epoch: 062, Loss: 0.2098, Val AP: 0.9420, Val AUC: 0.8921\r\n",
      "Epoch: 063, Loss: 0.2089, Val AP: 0.9401, Val AUC: 0.8900\r\n",
      "Epoch: 064, Loss: 0.2083, Val AP: 0.9413, Val AUC: 0.8915\r\n",
      "Epoch: 065, Loss: 0.2084, Val AP: 0.9374, Val AUC: 0.8864\r\n",
      "Epoch: 066, Loss: 0.2081, Val AP: 0.9426, Val AUC: 0.8933\r\n",
      "Epoch: 067, Loss: 0.2083, Val AP: 0.9426, Val AUC: 0.8938\r\n",
      "Epoch: 068, Loss: 0.2074, Val AP: 0.9417, Val AUC: 0.8929\r\n",
      "Epoch: 069, Loss: 0.2063, Val AP: 0.9423, Val AUC: 0.8923\r\n",
      "Epoch: 070, Loss: 0.2077, Val AP: 0.9437, Val AUC: 0.8927\r\n",
      "Epoch: 071, Loss: 0.2084, Val AP: 0.9429, Val AUC: 0.8922\r\n",
      "Epoch: 072, Loss: 0.2067, Val AP: 0.9412, Val AUC: 0.8901\r\n",
      "Epoch: 073, Loss: 0.2081, Val AP: 0.9435, Val AUC: 0.8949\r\n",
      "Epoch: 074, Loss: 0.2074, Val AP: 0.9396, Val AUC: 0.8912\r\n",
      "Epoch: 075, Loss: 0.2064, Val AP: 0.9453, Val AUC: 0.8954\r\n",
      "Epoch: 076, Loss: 0.2070, Val AP: 0.9438, Val AUC: 0.8938\r\n",
      "Epoch: 077, Loss: 0.2062, Val AP: 0.9418, Val AUC: 0.8920\r\n",
      "Epoch: 078, Loss: 0.2074, Val AP: 0.9402, Val AUC: 0.8871\r\n",
      "Epoch: 079, Loss: 0.2078, Val AP: 0.9456, Val AUC: 0.8955\r\n",
      "Epoch: 080, Loss: 0.2057, Val AP: 0.9408, Val AUC: 0.8920\r\n",
      "Epoch: 081, Loss: 0.2055, Val AP: 0.9415, Val AUC: 0.8912\r\n",
      "Epoch: 082, Loss: 0.2051, Val AP: 0.9451, Val AUC: 0.8970\r\n",
      "Epoch: 083, Loss: 0.2045, Val AP: 0.9449, Val AUC: 0.8961\r\n",
      "Epoch: 084, Loss: 0.2048, Val AP: 0.9444, Val AUC: 0.8954\r\n",
      "Epoch: 085, Loss: 0.2050, Val AP: 0.9454, Val AUC: 0.8967\r\n",
      "Epoch: 086, Loss: 0.2046, Val AP: 0.9464, Val AUC: 0.8975\r\n",
      "Epoch: 087, Loss: 0.2035, Val AP: 0.9464, Val AUC: 0.8977\r\n",
      "Epoch: 088, Loss: 0.2052, Val AP: 0.9444, Val AUC: 0.8967\r\n",
      "Epoch: 089, Loss: 0.2044, Val AP: 0.9462, Val AUC: 0.8993\r\n",
      "Epoch: 090, Loss: 0.2038, Val AP: 0.9457, Val AUC: 0.8970\r\n",
      "Epoch: 091, Loss: 0.2027, Val AP: 0.9467, Val AUC: 0.8977\r\n",
      "Epoch: 092, Loss: 0.2034, Val AP: 0.9448, Val AUC: 0.8945\r\n",
      "Epoch: 093, Loss: 0.2043, Val AP: 0.9476, Val AUC: 0.9001\r\n",
      "Epoch: 094, Loss: 0.2016, Val AP: 0.9449, Val AUC: 0.8966\r\n",
      "Epoch: 095, Loss: 0.2030, Val AP: 0.9476, Val AUC: 0.8996\r\n",
      "Epoch: 096, Loss: 0.2033, Val AP: 0.9456, Val AUC: 0.8961\r\n",
      "Epoch: 097, Loss: 0.2040, Val AP: 0.9475, Val AUC: 0.8982\r\n",
      "Epoch: 098, Loss: 0.2020, Val AP: 0.9474, Val AUC: 0.8994\r\n",
      "Epoch: 099, Loss: 0.2021, Val AP: 0.9479, Val AUC: 0.8988\r\n",
      "Epoch: 100, Loss: 0.2026, Val AP: 0.9485, Val AUC: 0.9021\r\n",
      "Loading best model for final evaluation (best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.9021578108021482, 'AP': 0.9485251913850598, 'F1': 0.8476641841570753, 'F0.5': 0.8937749857224444}\r\n",
      "\u001b[32m[I 2025-12-05 21:33:48,152]\u001b[0m Trial 14 finished with value: 0.9485251913850598 and parameters: {'hidden_dim': 32, 'heads': 8, 'layers': 3, 'dropout': 0.10908545556925323, 'lr': 0.0004990182763514062}. Best is trial 14 with value: 0.9485251913850598.\u001b[0m\r\n",
      "Optimization Complete.\r\n",
      "Best trial:\r\n",
      "  Value: 0.9485251913850598\r\n",
      "  Params: \r\n",
      "    hidden_dim: 32\r\n",
      "    heads: 8\r\n",
      "    layers: 3\r\n",
      "    dropout: 0.10908545556925323\r\n",
      "    lr: 0.0004990182763514062\r\n",
      "\r\n",
      "Optimization finished. You can now update src/config.py with these parameters.\r\n",
      "Pipeline Completed.\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --optimize --n_trials 15 --raw_file /kaggle/input/bindingdb-smiles/BindingDB_All.tsv --processed_dir ./data/processed\n",
    "#--cv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2520d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:33:49.971001Z",
     "iopub.status.busy": "2025-12-05T21:33:49.970475Z",
     "iopub.status.idle": "2025-12-05T21:33:49.978310Z",
     "shell.execute_reply": "2025-12-05T21:33:49.977580Z"
    },
    "papermill": {
     "duration": 0.076247,
     "end_time": "2025-12-05T21:33:49.979315",
     "exception": false,
     "start_time": "2025-12-05T21:33:49.903068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Nie znaleziono pliku ZIP. Upewnij się, że poprzednia komórka wykonała się bez błędów.\n",
      "Lista plików w obecnym folderze:\n",
      "['data', 'main.py', 'tests', 'src', 'requirements.txt', 'models', '.git', '.gitignore', 'plots']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Nazwa pliku, którego szukamy\n",
    "zip_name = 'GAT_BRD4_Results.zip'\n",
    "\n",
    "# 1. Znajdź plik w całym systemie plików roboczych\n",
    "found_path = None\n",
    "for root, dirs, files in os.walk('/kaggle/working'):\n",
    "    if zip_name in files:\n",
    "        found_path = os.path.join(root, zip_name)\n",
    "        break\n",
    "\n",
    "if found_path:\n",
    "    print(f\"✅ Znaleziono plik tutaj: {found_path}\")\n",
    "    \n",
    "    # 2. Przenieś go do głównego katalogu (Dla pewności)\n",
    "    target_path = f'/kaggle/working/{zip_name}'\n",
    "    \n",
    "    if found_path != target_path:\n",
    "        shutil.move(found_path, target_path)\n",
    "        print(f\"📦 Przeniesiono plik do głównego katalogu: {target_path}\")\n",
    "    \n",
    "    # 3. Zmień katalog roboczy na główny (żeby FileLink zadziałał)\n",
    "    os.chdir('/kaggle/working')\n",
    "    \n",
    "    # 4. Wyświetl link\n",
    "    print(\"👇 Kliknij poniżej:\")\n",
    "    display(FileLink(zip_name))\n",
    "else:\n",
    "    print(\"❌ Nie znaleziono pliku ZIP. Upewnij się, że poprzednia komórka wykonała się bez błędów.\")\n",
    "    # Sprawdźmy co w ogóle mamy na dysku\n",
    "    print(\"Lista plików w obecnym folderze:\")\n",
    "    print(os.listdir('.'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8899363,
     "sourceId": 13960890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6402.163832,
   "end_time": "2025-12-05T21:33:51.365426",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T19:47:09.201594",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
